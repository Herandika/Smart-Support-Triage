{
  "best_metric": 0.6979219533340298,
  "best_model_checkpoint": "models\\sentiment_distilbert\\hf_outputs\\checkpoint-5702",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5702,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008768853034023149,
      "grad_norm": 2.78609037399292,
      "learning_rate": 1.994154097977318e-05,
      "loss": 1.0106,
      "step": 50
    },
    {
      "epoch": 0.017537706068046298,
      "grad_norm": 4.405348777770996,
      "learning_rate": 1.988308195954636e-05,
      "loss": 0.9605,
      "step": 100
    },
    {
      "epoch": 0.02630655910206945,
      "grad_norm": 5.132295608520508,
      "learning_rate": 1.9825792119724076e-05,
      "loss": 0.863,
      "step": 150
    },
    {
      "epoch": 0.035075412136092596,
      "grad_norm": 15.297231674194336,
      "learning_rate": 1.9767333099497254e-05,
      "loss": 0.7744,
      "step": 200
    },
    {
      "epoch": 0.04384426517011575,
      "grad_norm": 8.914892196655273,
      "learning_rate": 1.971004325967497e-05,
      "loss": 0.8002,
      "step": 250
    },
    {
      "epoch": 0.0526131182041389,
      "grad_norm": 6.1103620529174805,
      "learning_rate": 1.965158423944815e-05,
      "loss": 0.7363,
      "step": 300
    },
    {
      "epoch": 0.061381971238162046,
      "grad_norm": 10.307082176208496,
      "learning_rate": 1.9593125219221328e-05,
      "loss": 0.716,
      "step": 350
    },
    {
      "epoch": 0.07015082427218519,
      "grad_norm": 6.216363906860352,
      "learning_rate": 1.953466619899451e-05,
      "loss": 0.8027,
      "step": 400
    },
    {
      "epoch": 0.07891967730620834,
      "grad_norm": 7.623715400695801,
      "learning_rate": 1.9476207178767687e-05,
      "loss": 0.7357,
      "step": 450
    },
    {
      "epoch": 0.0876885303402315,
      "grad_norm": 5.970484256744385,
      "learning_rate": 1.9417748158540864e-05,
      "loss": 0.7109,
      "step": 500
    },
    {
      "epoch": 0.09645738337425465,
      "grad_norm": 8.468155860900879,
      "learning_rate": 1.9359289138314042e-05,
      "loss": 0.7474,
      "step": 550
    },
    {
      "epoch": 0.1052262364082778,
      "grad_norm": 5.409418106079102,
      "learning_rate": 1.930083011808722e-05,
      "loss": 0.6828,
      "step": 600
    },
    {
      "epoch": 0.11399508944230095,
      "grad_norm": 9.056489944458008,
      "learning_rate": 1.92423710978604e-05,
      "loss": 0.7383,
      "step": 650
    },
    {
      "epoch": 0.12276394247632409,
      "grad_norm": 7.209068298339844,
      "learning_rate": 1.918391207763358e-05,
      "loss": 0.7533,
      "step": 700
    },
    {
      "epoch": 0.13153279551034724,
      "grad_norm": 11.150015830993652,
      "learning_rate": 1.912545305740676e-05,
      "loss": 0.7387,
      "step": 750
    },
    {
      "epoch": 0.14030164854437038,
      "grad_norm": 11.48244857788086,
      "learning_rate": 1.9066994037179938e-05,
      "loss": 0.736,
      "step": 800
    },
    {
      "epoch": 0.14907050157839355,
      "grad_norm": 10.70394229888916,
      "learning_rate": 1.900853501695312e-05,
      "loss": 0.6696,
      "step": 850
    },
    {
      "epoch": 0.1578393546124167,
      "grad_norm": 9.964875221252441,
      "learning_rate": 1.8950075996726297e-05,
      "loss": 0.6694,
      "step": 900
    },
    {
      "epoch": 0.16660820764643985,
      "grad_norm": 6.128086090087891,
      "learning_rate": 1.8891616976499478e-05,
      "loss": 0.7266,
      "step": 950
    },
    {
      "epoch": 0.175377060680463,
      "grad_norm": 8.196494102478027,
      "learning_rate": 1.8833157956272656e-05,
      "loss": 0.7679,
      "step": 1000
    },
    {
      "epoch": 0.18414591371448616,
      "grad_norm": 3.785667896270752,
      "learning_rate": 1.8774698936045833e-05,
      "loss": 0.7697,
      "step": 1050
    },
    {
      "epoch": 0.1929147667485093,
      "grad_norm": 6.847892761230469,
      "learning_rate": 1.871623991581901e-05,
      "loss": 0.6864,
      "step": 1100
    },
    {
      "epoch": 0.20168361978253244,
      "grad_norm": 11.189318656921387,
      "learning_rate": 1.8657780895592192e-05,
      "loss": 0.6862,
      "step": 1150
    },
    {
      "epoch": 0.2104524728165556,
      "grad_norm": 12.154191017150879,
      "learning_rate": 1.859932187536537e-05,
      "loss": 0.7452,
      "step": 1200
    },
    {
      "epoch": 0.21922132585057874,
      "grad_norm": 9.27708625793457,
      "learning_rate": 1.8540862855138548e-05,
      "loss": 0.7231,
      "step": 1250
    },
    {
      "epoch": 0.2279901788846019,
      "grad_norm": 11.412940979003906,
      "learning_rate": 1.848240383491173e-05,
      "loss": 0.739,
      "step": 1300
    },
    {
      "epoch": 0.23675903191862505,
      "grad_norm": 7.650617599487305,
      "learning_rate": 1.8423944814684907e-05,
      "loss": 0.689,
      "step": 1350
    },
    {
      "epoch": 0.24552788495264818,
      "grad_norm": 10.387537956237793,
      "learning_rate": 1.8365485794458088e-05,
      "loss": 0.7143,
      "step": 1400
    },
    {
      "epoch": 0.25429673798667135,
      "grad_norm": 5.376278400421143,
      "learning_rate": 1.8307026774231266e-05,
      "loss": 0.6391,
      "step": 1450
    },
    {
      "epoch": 0.2630655910206945,
      "grad_norm": 6.430680751800537,
      "learning_rate": 1.8248567754004443e-05,
      "loss": 0.7101,
      "step": 1500
    },
    {
      "epoch": 0.2718344440547176,
      "grad_norm": 11.026700973510742,
      "learning_rate": 1.819010873377762e-05,
      "loss": 0.6436,
      "step": 1550
    },
    {
      "epoch": 0.28060329708874077,
      "grad_norm": 19.28641700744629,
      "learning_rate": 1.8131649713550802e-05,
      "loss": 0.6819,
      "step": 1600
    },
    {
      "epoch": 0.28937215012276396,
      "grad_norm": 6.342319965362549,
      "learning_rate": 1.807319069332398e-05,
      "loss": 0.6486,
      "step": 1650
    },
    {
      "epoch": 0.2981410031567871,
      "grad_norm": 6.3827972412109375,
      "learning_rate": 1.801473167309716e-05,
      "loss": 0.6929,
      "step": 1700
    },
    {
      "epoch": 0.30690985619081024,
      "grad_norm": 6.503917217254639,
      "learning_rate": 1.795627265287034e-05,
      "loss": 0.7055,
      "step": 1750
    },
    {
      "epoch": 0.3156787092248334,
      "grad_norm": 7.862295627593994,
      "learning_rate": 1.789781363264352e-05,
      "loss": 0.624,
      "step": 1800
    },
    {
      "epoch": 0.3244475622588565,
      "grad_norm": 10.600494384765625,
      "learning_rate": 1.7839354612416698e-05,
      "loss": 0.6908,
      "step": 1850
    },
    {
      "epoch": 0.3332164152928797,
      "grad_norm": 13.644340515136719,
      "learning_rate": 1.778089559218988e-05,
      "loss": 0.6094,
      "step": 1900
    },
    {
      "epoch": 0.34198526832690285,
      "grad_norm": 6.878085136413574,
      "learning_rate": 1.7722436571963057e-05,
      "loss": 0.6287,
      "step": 1950
    },
    {
      "epoch": 0.350754121360926,
      "grad_norm": 8.99931812286377,
      "learning_rate": 1.7663977551736234e-05,
      "loss": 0.7207,
      "step": 2000
    },
    {
      "epoch": 0.3595229743949491,
      "grad_norm": 7.750284194946289,
      "learning_rate": 1.7605518531509412e-05,
      "loss": 0.6799,
      "step": 2050
    },
    {
      "epoch": 0.3682918274289723,
      "grad_norm": 11.2012939453125,
      "learning_rate": 1.754705951128259e-05,
      "loss": 0.6887,
      "step": 2100
    },
    {
      "epoch": 0.37706068046299546,
      "grad_norm": 12.072850227355957,
      "learning_rate": 1.748860049105577e-05,
      "loss": 0.6388,
      "step": 2150
    },
    {
      "epoch": 0.3858295334970186,
      "grad_norm": 9.421682357788086,
      "learning_rate": 1.743014147082895e-05,
      "loss": 0.6253,
      "step": 2200
    },
    {
      "epoch": 0.39459838653104173,
      "grad_norm": 15.51858139038086,
      "learning_rate": 1.737168245060213e-05,
      "loss": 0.6344,
      "step": 2250
    },
    {
      "epoch": 0.4033672395650649,
      "grad_norm": 8.501811981201172,
      "learning_rate": 1.7313223430375308e-05,
      "loss": 0.7072,
      "step": 2300
    },
    {
      "epoch": 0.41213609259908807,
      "grad_norm": 9.413457870483398,
      "learning_rate": 1.725476441014849e-05,
      "loss": 0.6721,
      "step": 2350
    },
    {
      "epoch": 0.4209049456331112,
      "grad_norm": 12.418612480163574,
      "learning_rate": 1.71974745703262e-05,
      "loss": 0.6842,
      "step": 2400
    },
    {
      "epoch": 0.42967379866713434,
      "grad_norm": 6.502837657928467,
      "learning_rate": 1.7139015550099382e-05,
      "loss": 0.622,
      "step": 2450
    },
    {
      "epoch": 0.4384426517011575,
      "grad_norm": 6.329768180847168,
      "learning_rate": 1.708055652987256e-05,
      "loss": 0.7045,
      "step": 2500
    },
    {
      "epoch": 0.4472115047351806,
      "grad_norm": 6.963382244110107,
      "learning_rate": 1.702209750964574e-05,
      "loss": 0.67,
      "step": 2550
    },
    {
      "epoch": 0.4559803577692038,
      "grad_norm": 4.712369918823242,
      "learning_rate": 1.696363848941892e-05,
      "loss": 0.6054,
      "step": 2600
    },
    {
      "epoch": 0.46474921080322695,
      "grad_norm": 9.84788990020752,
      "learning_rate": 1.6905179469192096e-05,
      "loss": 0.7212,
      "step": 2650
    },
    {
      "epoch": 0.4735180638372501,
      "grad_norm": 5.696516036987305,
      "learning_rate": 1.6846720448965278e-05,
      "loss": 0.6353,
      "step": 2700
    },
    {
      "epoch": 0.48228691687127323,
      "grad_norm": 7.9802327156066895,
      "learning_rate": 1.6788261428738455e-05,
      "loss": 0.7168,
      "step": 2750
    },
    {
      "epoch": 0.49105576990529637,
      "grad_norm": 11.6334228515625,
      "learning_rate": 1.6729802408511636e-05,
      "loss": 0.6892,
      "step": 2800
    },
    {
      "epoch": 0.49982462293931956,
      "grad_norm": 6.101984977722168,
      "learning_rate": 1.6671343388284814e-05,
      "loss": 0.5988,
      "step": 2850
    },
    {
      "epoch": 0.5085934759733427,
      "grad_norm": 13.859321594238281,
      "learning_rate": 1.6612884368057992e-05,
      "loss": 0.691,
      "step": 2900
    },
    {
      "epoch": 0.5173623290073658,
      "grad_norm": 9.972716331481934,
      "learning_rate": 1.655442534783117e-05,
      "loss": 0.6425,
      "step": 2950
    },
    {
      "epoch": 0.526131182041389,
      "grad_norm": 7.131099700927734,
      "learning_rate": 1.649596632760435e-05,
      "loss": 0.645,
      "step": 3000
    },
    {
      "epoch": 0.5349000350754122,
      "grad_norm": 9.994009017944336,
      "learning_rate": 1.643750730737753e-05,
      "loss": 0.5886,
      "step": 3050
    },
    {
      "epoch": 0.5436688881094353,
      "grad_norm": 5.116741180419922,
      "learning_rate": 1.637904828715071e-05,
      "loss": 0.7059,
      "step": 3100
    },
    {
      "epoch": 0.5524377411434584,
      "grad_norm": 6.788241863250732,
      "learning_rate": 1.6320589266923888e-05,
      "loss": 0.6098,
      "step": 3150
    },
    {
      "epoch": 0.5612065941774815,
      "grad_norm": 9.483665466308594,
      "learning_rate": 1.626213024669707e-05,
      "loss": 0.7098,
      "step": 3200
    },
    {
      "epoch": 0.5699754472115047,
      "grad_norm": 8.083919525146484,
      "learning_rate": 1.6203671226470246e-05,
      "loss": 0.653,
      "step": 3250
    },
    {
      "epoch": 0.5787443002455279,
      "grad_norm": 7.0439958572387695,
      "learning_rate": 1.6145212206243424e-05,
      "loss": 0.6161,
      "step": 3300
    },
    {
      "epoch": 0.587513153279551,
      "grad_norm": 5.529977798461914,
      "learning_rate": 1.6086753186016605e-05,
      "loss": 0.6665,
      "step": 3350
    },
    {
      "epoch": 0.5962820063135742,
      "grad_norm": 10.408880233764648,
      "learning_rate": 1.6028294165789783e-05,
      "loss": 0.6141,
      "step": 3400
    },
    {
      "epoch": 0.6050508593475973,
      "grad_norm": 10.851572036743164,
      "learning_rate": 1.596983514556296e-05,
      "loss": 0.5766,
      "step": 3450
    },
    {
      "epoch": 0.6138197123816205,
      "grad_norm": 8.411799430847168,
      "learning_rate": 1.591137612533614e-05,
      "loss": 0.7359,
      "step": 3500
    },
    {
      "epoch": 0.6225885654156437,
      "grad_norm": 6.488907337188721,
      "learning_rate": 1.585291710510932e-05,
      "loss": 0.6549,
      "step": 3550
    },
    {
      "epoch": 0.6313574184496668,
      "grad_norm": 10.763432502746582,
      "learning_rate": 1.5794458084882498e-05,
      "loss": 0.6894,
      "step": 3600
    },
    {
      "epoch": 0.64012627148369,
      "grad_norm": 9.205035209655762,
      "learning_rate": 1.573599906465568e-05,
      "loss": 0.632,
      "step": 3650
    },
    {
      "epoch": 0.648895124517713,
      "grad_norm": 12.431971549987793,
      "learning_rate": 1.5677540044428856e-05,
      "loss": 0.6312,
      "step": 3700
    },
    {
      "epoch": 0.6576639775517362,
      "grad_norm": 13.151571273803711,
      "learning_rate": 1.5619081024202038e-05,
      "loss": 0.6654,
      "step": 3750
    },
    {
      "epoch": 0.6664328305857594,
      "grad_norm": 8.816189765930176,
      "learning_rate": 1.5560622003975215e-05,
      "loss": 0.6495,
      "step": 3800
    },
    {
      "epoch": 0.6752016836197825,
      "grad_norm": 7.93595552444458,
      "learning_rate": 1.5502162983748393e-05,
      "loss": 0.613,
      "step": 3850
    },
    {
      "epoch": 0.6839705366538057,
      "grad_norm": 7.239200592041016,
      "learning_rate": 1.544370396352157e-05,
      "loss": 0.674,
      "step": 3900
    },
    {
      "epoch": 0.6927393896878288,
      "grad_norm": 7.882876873016357,
      "learning_rate": 1.5385244943294752e-05,
      "loss": 0.6345,
      "step": 3950
    },
    {
      "epoch": 0.701508242721852,
      "grad_norm": 6.4954833984375,
      "learning_rate": 1.532678592306793e-05,
      "loss": 0.7186,
      "step": 4000
    },
    {
      "epoch": 0.7102770957558752,
      "grad_norm": 4.600713729858398,
      "learning_rate": 1.5268326902841107e-05,
      "loss": 0.6289,
      "step": 4050
    },
    {
      "epoch": 0.7190459487898982,
      "grad_norm": 10.321553230285645,
      "learning_rate": 1.5209867882614289e-05,
      "loss": 0.5809,
      "step": 4100
    },
    {
      "epoch": 0.7278148018239214,
      "grad_norm": 9.643561363220215,
      "learning_rate": 1.5151408862387466e-05,
      "loss": 0.6228,
      "step": 4150
    },
    {
      "epoch": 0.7365836548579446,
      "grad_norm": 7.35713529586792,
      "learning_rate": 1.5092949842160648e-05,
      "loss": 0.6373,
      "step": 4200
    },
    {
      "epoch": 0.7453525078919677,
      "grad_norm": 4.078065395355225,
      "learning_rate": 1.5034490821933825e-05,
      "loss": 0.6535,
      "step": 4250
    },
    {
      "epoch": 0.7541213609259909,
      "grad_norm": 6.547789096832275,
      "learning_rate": 1.4976031801707005e-05,
      "loss": 0.644,
      "step": 4300
    },
    {
      "epoch": 0.762890213960014,
      "grad_norm": 3.811894178390503,
      "learning_rate": 1.4917572781480183e-05,
      "loss": 0.6566,
      "step": 4350
    },
    {
      "epoch": 0.7716590669940372,
      "grad_norm": 7.036433219909668,
      "learning_rate": 1.4859113761253364e-05,
      "loss": 0.6045,
      "step": 4400
    },
    {
      "epoch": 0.7804279200280604,
      "grad_norm": 9.200966835021973,
      "learning_rate": 1.4800654741026541e-05,
      "loss": 0.6145,
      "step": 4450
    },
    {
      "epoch": 0.7891967730620835,
      "grad_norm": 8.785243034362793,
      "learning_rate": 1.4742195720799721e-05,
      "loss": 0.6161,
      "step": 4500
    },
    {
      "epoch": 0.7979656260961067,
      "grad_norm": 13.086260795593262,
      "learning_rate": 1.4683736700572899e-05,
      "loss": 0.6052,
      "step": 4550
    },
    {
      "epoch": 0.8067344791301297,
      "grad_norm": 6.894944190979004,
      "learning_rate": 1.4626446860750616e-05,
      "loss": 0.63,
      "step": 4600
    },
    {
      "epoch": 0.8155033321641529,
      "grad_norm": 7.988692760467529,
      "learning_rate": 1.4567987840523793e-05,
      "loss": 0.5769,
      "step": 4650
    },
    {
      "epoch": 0.8242721851981761,
      "grad_norm": 9.271968841552734,
      "learning_rate": 1.4509528820296971e-05,
      "loss": 0.6251,
      "step": 4700
    },
    {
      "epoch": 0.8330410382321992,
      "grad_norm": 13.432433128356934,
      "learning_rate": 1.4451069800070152e-05,
      "loss": 0.6311,
      "step": 4750
    },
    {
      "epoch": 0.8418098912662224,
      "grad_norm": 19.611053466796875,
      "learning_rate": 1.439261077984333e-05,
      "loss": 0.6351,
      "step": 4800
    },
    {
      "epoch": 0.8505787443002455,
      "grad_norm": 17.896814346313477,
      "learning_rate": 1.433415175961651e-05,
      "loss": 0.5976,
      "step": 4850
    },
    {
      "epoch": 0.8593475973342687,
      "grad_norm": 9.070780754089355,
      "learning_rate": 1.4275692739389689e-05,
      "loss": 0.5921,
      "step": 4900
    },
    {
      "epoch": 0.8681164503682919,
      "grad_norm": 5.377007961273193,
      "learning_rate": 1.4217233719162868e-05,
      "loss": 0.6235,
      "step": 4950
    },
    {
      "epoch": 0.876885303402315,
      "grad_norm": 7.689847946166992,
      "learning_rate": 1.4158774698936046e-05,
      "loss": 0.6526,
      "step": 5000
    },
    {
      "epoch": 0.8856541564363382,
      "grad_norm": 8.640979766845703,
      "learning_rate": 1.4100315678709227e-05,
      "loss": 0.6752,
      "step": 5050
    },
    {
      "epoch": 0.8944230094703612,
      "grad_norm": 7.424570083618164,
      "learning_rate": 1.4041856658482405e-05,
      "loss": 0.6661,
      "step": 5100
    },
    {
      "epoch": 0.9031918625043844,
      "grad_norm": 20.304109573364258,
      "learning_rate": 1.3983397638255584e-05,
      "loss": 0.6471,
      "step": 5150
    },
    {
      "epoch": 0.9119607155384076,
      "grad_norm": 7.652063846588135,
      "learning_rate": 1.3924938618028762e-05,
      "loss": 0.635,
      "step": 5200
    },
    {
      "epoch": 0.9207295685724307,
      "grad_norm": 5.61309289932251,
      "learning_rate": 1.3866479597801943e-05,
      "loss": 0.6494,
      "step": 5250
    },
    {
      "epoch": 0.9294984216064539,
      "grad_norm": 11.51627254486084,
      "learning_rate": 1.3808020577575121e-05,
      "loss": 0.6111,
      "step": 5300
    },
    {
      "epoch": 0.938267274640477,
      "grad_norm": 8.385472297668457,
      "learning_rate": 1.37495615573483e-05,
      "loss": 0.6093,
      "step": 5350
    },
    {
      "epoch": 0.9470361276745002,
      "grad_norm": 7.989416599273682,
      "learning_rate": 1.3691102537121478e-05,
      "loss": 0.6081,
      "step": 5400
    },
    {
      "epoch": 0.9558049807085234,
      "grad_norm": 5.929741382598877,
      "learning_rate": 1.3632643516894656e-05,
      "loss": 0.5634,
      "step": 5450
    },
    {
      "epoch": 0.9645738337425465,
      "grad_norm": 8.158644676208496,
      "learning_rate": 1.3574184496667837e-05,
      "loss": 0.5934,
      "step": 5500
    },
    {
      "epoch": 0.9733426867765697,
      "grad_norm": 5.380097389221191,
      "learning_rate": 1.3515725476441015e-05,
      "loss": 0.6121,
      "step": 5550
    },
    {
      "epoch": 0.9821115398105927,
      "grad_norm": 12.424233436584473,
      "learning_rate": 1.3457266456214194e-05,
      "loss": 0.6257,
      "step": 5600
    },
    {
      "epoch": 0.9908803928446159,
      "grad_norm": 6.425619125366211,
      "learning_rate": 1.3398807435987374e-05,
      "loss": 0.595,
      "step": 5650
    },
    {
      "epoch": 0.9996492458786391,
      "grad_norm": 6.724080562591553,
      "learning_rate": 1.3340348415760553e-05,
      "loss": 0.642,
      "step": 5700
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6979219533340298,
      "eval_loss": 0.6643175482749939,
      "eval_runtime": 160.8306,
      "eval_samples_per_second": 76.378,
      "eval_steps_per_second": 9.55,
      "step": 5702
    }
  ],
  "logging_steps": 50,
  "max_steps": 17106,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 498263790231612.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

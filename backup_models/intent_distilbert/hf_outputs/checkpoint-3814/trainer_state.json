{
  "best_metric": 0.8927965627583531,
  "best_model_checkpoint": "models\\intent_distilbert\\hf_outputs\\checkpoint-3814",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3814,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026219192448872573,
      "grad_norm": 3.4074909687042236,
      "learning_rate": 1.9825205383674183e-05,
      "loss": 5.0129,
      "step": 50
    },
    {
      "epoch": 0.05243838489774515,
      "grad_norm": 4.635189533233643,
      "learning_rate": 1.9650410767348368e-05,
      "loss": 4.9562,
      "step": 100
    },
    {
      "epoch": 0.07865757734661773,
      "grad_norm": 5.334802627563477,
      "learning_rate": 1.947561615102255e-05,
      "loss": 4.88,
      "step": 150
    },
    {
      "epoch": 0.1048767697954903,
      "grad_norm": 5.979557991027832,
      "learning_rate": 1.930082153469673e-05,
      "loss": 4.7579,
      "step": 200
    },
    {
      "epoch": 0.13109596224436287,
      "grad_norm": 6.145437240600586,
      "learning_rate": 1.9126026918370913e-05,
      "loss": 4.6417,
      "step": 250
    },
    {
      "epoch": 0.15731515469323545,
      "grad_norm": 6.342186450958252,
      "learning_rate": 1.8951232302045098e-05,
      "loss": 4.4893,
      "step": 300
    },
    {
      "epoch": 0.18353434714210803,
      "grad_norm": 6.720129489898682,
      "learning_rate": 1.8776437685719283e-05,
      "loss": 4.3518,
      "step": 350
    },
    {
      "epoch": 0.2097535395909806,
      "grad_norm": 6.180408954620361,
      "learning_rate": 1.8601643069393465e-05,
      "loss": 4.2242,
      "step": 400
    },
    {
      "epoch": 0.23597273203985317,
      "grad_norm": 7.015050888061523,
      "learning_rate": 1.8426848453067646e-05,
      "loss": 4.0495,
      "step": 450
    },
    {
      "epoch": 0.26219192448872575,
      "grad_norm": 7.398268222808838,
      "learning_rate": 1.825205383674183e-05,
      "loss": 3.9251,
      "step": 500
    },
    {
      "epoch": 0.2884111169375983,
      "grad_norm": 7.252114295959473,
      "learning_rate": 1.8077259220416013e-05,
      "loss": 3.7802,
      "step": 550
    },
    {
      "epoch": 0.3146303093864709,
      "grad_norm": 7.438183307647705,
      "learning_rate": 1.7902464604090195e-05,
      "loss": 3.7123,
      "step": 600
    },
    {
      "epoch": 0.34084950183534346,
      "grad_norm": 7.859275817871094,
      "learning_rate": 1.7727669987764376e-05,
      "loss": 3.4836,
      "step": 650
    },
    {
      "epoch": 0.36706869428421607,
      "grad_norm": 7.805804252624512,
      "learning_rate": 1.755287537143856e-05,
      "loss": 3.3962,
      "step": 700
    },
    {
      "epoch": 0.3932878867330886,
      "grad_norm": 9.393327713012695,
      "learning_rate": 1.7378080755112743e-05,
      "loss": 3.2405,
      "step": 750
    },
    {
      "epoch": 0.4195070791819612,
      "grad_norm": 8.873008728027344,
      "learning_rate": 1.7203286138786928e-05,
      "loss": 3.1313,
      "step": 800
    },
    {
      "epoch": 0.4457262716308338,
      "grad_norm": 9.055481910705566,
      "learning_rate": 1.702849152246111e-05,
      "loss": 3.01,
      "step": 850
    },
    {
      "epoch": 0.47194546407970633,
      "grad_norm": 10.778457641601562,
      "learning_rate": 1.685369690613529e-05,
      "loss": 2.8965,
      "step": 900
    },
    {
      "epoch": 0.49816465652857894,
      "grad_norm": 9.322293281555176,
      "learning_rate": 1.6678902289809476e-05,
      "loss": 2.7984,
      "step": 950
    },
    {
      "epoch": 0.5243838489774515,
      "grad_norm": 10.097596168518066,
      "learning_rate": 1.6504107673483658e-05,
      "loss": 2.6763,
      "step": 1000
    },
    {
      "epoch": 0.5506030414263241,
      "grad_norm": 9.632770538330078,
      "learning_rate": 1.632931305715784e-05,
      "loss": 2.5972,
      "step": 1050
    },
    {
      "epoch": 0.5768222338751966,
      "grad_norm": 9.166999816894531,
      "learning_rate": 1.6154518440832024e-05,
      "loss": 2.4613,
      "step": 1100
    },
    {
      "epoch": 0.6030414263240692,
      "grad_norm": 10.514389991760254,
      "learning_rate": 1.5979723824506206e-05,
      "loss": 2.2902,
      "step": 1150
    },
    {
      "epoch": 0.6292606187729418,
      "grad_norm": 9.24748706817627,
      "learning_rate": 1.5804929208180388e-05,
      "loss": 2.2476,
      "step": 1200
    },
    {
      "epoch": 0.6554798112218144,
      "grad_norm": 8.276861190795898,
      "learning_rate": 1.5630134591854573e-05,
      "loss": 2.113,
      "step": 1250
    },
    {
      "epoch": 0.6816990036706869,
      "grad_norm": 9.379281997680664,
      "learning_rate": 1.545883586785527e-05,
      "loss": 1.9913,
      "step": 1300
    },
    {
      "epoch": 0.7079181961195595,
      "grad_norm": Infinity,
      "learning_rate": 1.528753714385597e-05,
      "loss": 1.9805,
      "step": 1350
    },
    {
      "epoch": 0.7341373885684321,
      "grad_norm": 10.03986644744873,
      "learning_rate": 1.5112742527530153e-05,
      "loss": 1.8844,
      "step": 1400
    },
    {
      "epoch": 0.7603565810173046,
      "grad_norm": 8.428816795349121,
      "learning_rate": 1.4937947911204336e-05,
      "loss": 1.789,
      "step": 1450
    },
    {
      "epoch": 0.7865757734661772,
      "grad_norm": 9.4177885055542,
      "learning_rate": 1.4763153294878518e-05,
      "loss": 1.6473,
      "step": 1500
    },
    {
      "epoch": 0.8127949659150498,
      "grad_norm": 11.008284568786621,
      "learning_rate": 1.4588358678552701e-05,
      "loss": 1.5994,
      "step": 1550
    },
    {
      "epoch": 0.8390141583639223,
      "grad_norm": 9.087879180908203,
      "learning_rate": 1.4413564062226884e-05,
      "loss": 1.5483,
      "step": 1600
    },
    {
      "epoch": 0.865233350812795,
      "grad_norm": 7.830358505249023,
      "learning_rate": 1.4238769445901068e-05,
      "loss": 1.4841,
      "step": 1650
    },
    {
      "epoch": 0.8914525432616676,
      "grad_norm": 8.461018562316895,
      "learning_rate": 1.4063974829575251e-05,
      "loss": 1.4265,
      "step": 1700
    },
    {
      "epoch": 0.9176717357105402,
      "grad_norm": 13.396951675415039,
      "learning_rate": 1.3889180213249434e-05,
      "loss": 1.33,
      "step": 1750
    },
    {
      "epoch": 0.9438909281594127,
      "grad_norm": 11.218741416931152,
      "learning_rate": 1.3714385596923616e-05,
      "loss": 1.2393,
      "step": 1800
    },
    {
      "epoch": 0.9701101206082853,
      "grad_norm": 9.90153980255127,
      "learning_rate": 1.35395909805978e-05,
      "loss": 1.2323,
      "step": 1850
    },
    {
      "epoch": 0.9963293130571579,
      "grad_norm": 8.049281120300293,
      "learning_rate": 1.3364796364271981e-05,
      "loss": 1.1652,
      "step": 1900
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.8271168569565277,
      "eval_loss": 1.328100323677063,
      "eval_runtime": 37.2669,
      "eval_samples_per_second": 147.584,
      "eval_steps_per_second": 18.461,
      "step": 1907
    },
    {
      "epoch": 1.0225485055060304,
      "grad_norm": 8.292374610900879,
      "learning_rate": 1.3190001747946164e-05,
      "loss": 1.0324,
      "step": 1950
    },
    {
      "epoch": 1.048767697954903,
      "grad_norm": 6.797926902770996,
      "learning_rate": 1.3015207131620346e-05,
      "loss": 0.9602,
      "step": 2000
    },
    {
      "epoch": 1.0749868904037756,
      "grad_norm": 7.700553894042969,
      "learning_rate": 1.2840412515294529e-05,
      "loss": 0.9333,
      "step": 2050
    },
    {
      "epoch": 1.1012060828526482,
      "grad_norm": 7.508955478668213,
      "learning_rate": 1.2665617898968712e-05,
      "loss": 0.8792,
      "step": 2100
    },
    {
      "epoch": 1.1274252753015208,
      "grad_norm": 7.735012054443359,
      "learning_rate": 1.2490823282642896e-05,
      "loss": 0.8731,
      "step": 2150
    },
    {
      "epoch": 1.1536444677503932,
      "grad_norm": 5.822161674499512,
      "learning_rate": 1.2316028666317079e-05,
      "loss": 0.8316,
      "step": 2200
    },
    {
      "epoch": 1.1798636601992658,
      "grad_norm": 8.447375297546387,
      "learning_rate": 1.2141234049991262e-05,
      "loss": 0.8033,
      "step": 2250
    },
    {
      "epoch": 1.2060828526481384,
      "grad_norm": 6.758462429046631,
      "learning_rate": 1.1966439433665444e-05,
      "loss": 0.7627,
      "step": 2300
    },
    {
      "epoch": 1.232302045097011,
      "grad_norm": 7.7113423347473145,
      "learning_rate": 1.1791644817339627e-05,
      "loss": 0.7633,
      "step": 2350
    },
    {
      "epoch": 1.2585212375458836,
      "grad_norm": 5.458956718444824,
      "learning_rate": 1.1616850201013809e-05,
      "loss": 0.6697,
      "step": 2400
    },
    {
      "epoch": 1.2847404299947562,
      "grad_norm": 6.146956443786621,
      "learning_rate": 1.1442055584687992e-05,
      "loss": 0.6752,
      "step": 2450
    },
    {
      "epoch": 1.3109596224436286,
      "grad_norm": 7.642693042755127,
      "learning_rate": 1.1267260968362176e-05,
      "loss": 0.6573,
      "step": 2500
    },
    {
      "epoch": 1.3371788148925012,
      "grad_norm": 9.709936141967773,
      "learning_rate": 1.1092466352036357e-05,
      "loss": 0.6325,
      "step": 2550
    },
    {
      "epoch": 1.3633980073413738,
      "grad_norm": 13.537413597106934,
      "learning_rate": 1.091767173571054e-05,
      "loss": 0.6399,
      "step": 2600
    },
    {
      "epoch": 1.3896171997902464,
      "grad_norm": 5.589107036590576,
      "learning_rate": 1.0742877119384726e-05,
      "loss": 0.5857,
      "step": 2650
    },
    {
      "epoch": 1.415836392239119,
      "grad_norm": 10.75529956817627,
      "learning_rate": 1.0568082503058907e-05,
      "loss": 0.583,
      "step": 2700
    },
    {
      "epoch": 1.4420555846879917,
      "grad_norm": 9.332226753234863,
      "learning_rate": 1.039328788673309e-05,
      "loss": 0.551,
      "step": 2750
    },
    {
      "epoch": 1.4682747771368643,
      "grad_norm": 5.18365478515625,
      "learning_rate": 1.0218493270407272e-05,
      "loss": 0.5307,
      "step": 2800
    },
    {
      "epoch": 1.4944939695857369,
      "grad_norm": 9.2822265625,
      "learning_rate": 1.0043698654081455e-05,
      "loss": 0.4567,
      "step": 2850
    },
    {
      "epoch": 1.5207131620346095,
      "grad_norm": 5.50998592376709,
      "learning_rate": 9.868904037755637e-06,
      "loss": 0.4626,
      "step": 2900
    },
    {
      "epoch": 1.5469323544834819,
      "grad_norm": 6.652036190032959,
      "learning_rate": 9.69410942142982e-06,
      "loss": 0.4623,
      "step": 2950
    },
    {
      "epoch": 1.5731515469323545,
      "grad_norm": 14.94810676574707,
      "learning_rate": 9.519314805104004e-06,
      "loss": 0.4335,
      "step": 3000
    },
    {
      "epoch": 1.599370739381227,
      "grad_norm": 3.191926956176758,
      "learning_rate": 9.344520188778187e-06,
      "loss": 0.4081,
      "step": 3050
    },
    {
      "epoch": 1.6255899318300995,
      "grad_norm": 8.91841983795166,
      "learning_rate": 9.169725572452369e-06,
      "loss": 0.4237,
      "step": 3100
    },
    {
      "epoch": 1.651809124278972,
      "grad_norm": 3.7026991844177246,
      "learning_rate": 8.994930956126552e-06,
      "loss": 0.4317,
      "step": 3150
    },
    {
      "epoch": 1.6780283167278447,
      "grad_norm": 10.357438087463379,
      "learning_rate": 8.820136339800735e-06,
      "loss": 0.3856,
      "step": 3200
    },
    {
      "epoch": 1.7042475091767173,
      "grad_norm": 11.840551376342773,
      "learning_rate": 8.645341723474919e-06,
      "loss": 0.3535,
      "step": 3250
    },
    {
      "epoch": 1.73046670162559,
      "grad_norm": 7.789262771606445,
      "learning_rate": 8.4705471071491e-06,
      "loss": 0.3533,
      "step": 3300
    },
    {
      "epoch": 1.7566858940744625,
      "grad_norm": 16.458101272583008,
      "learning_rate": 8.295752490823283e-06,
      "loss": 0.3647,
      "step": 3350
    },
    {
      "epoch": 1.7829050865233351,
      "grad_norm": 6.105311393737793,
      "learning_rate": 8.120957874497467e-06,
      "loss": 0.363,
      "step": 3400
    },
    {
      "epoch": 1.8091242789722077,
      "grad_norm": 9.839187622070312,
      "learning_rate": 7.949659150498165e-06,
      "loss": 0.3916,
      "step": 3450
    },
    {
      "epoch": 1.8353434714210803,
      "grad_norm": 2.808289051055908,
      "learning_rate": 7.774864534172349e-06,
      "loss": 0.3996,
      "step": 3500
    },
    {
      "epoch": 1.861562663869953,
      "grad_norm": 4.1250081062316895,
      "learning_rate": 7.600069917846531e-06,
      "loss": 0.2887,
      "step": 3550
    },
    {
      "epoch": 1.8877818563188253,
      "grad_norm": 9.490358352661133,
      "learning_rate": 7.4252753015207135e-06,
      "loss": 0.3134,
      "step": 3600
    },
    {
      "epoch": 1.914001048767698,
      "grad_norm": 6.635740280151367,
      "learning_rate": 7.250480685194896e-06,
      "loss": 0.3259,
      "step": 3650
    },
    {
      "epoch": 1.9402202412165706,
      "grad_norm": 4.306214332580566,
      "learning_rate": 7.079181961195596e-06,
      "loss": 0.3504,
      "step": 3700
    },
    {
      "epoch": 1.9664394336654432,
      "grad_norm": 3.2458038330078125,
      "learning_rate": 6.9043873448697785e-06,
      "loss": 0.2942,
      "step": 3750
    },
    {
      "epoch": 1.9926586261143155,
      "grad_norm": 5.0500664710998535,
      "learning_rate": 6.729592728543961e-06,
      "loss": 0.2685,
      "step": 3800
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.8927965627583531,
      "eval_loss": 0.6435140371322632,
      "eval_runtime": 37.2301,
      "eval_samples_per_second": 147.73,
      "eval_steps_per_second": 18.48,
      "step": 3814
    }
  ],
  "logging_steps": 50,
  "max_steps": 5721,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 130949024666460.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

{
  "best_metric": 0.8271168569565277,
  "best_model_checkpoint": "models\\intent_distilbert\\hf_outputs\\checkpoint-1907",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1907,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026219192448872573,
      "grad_norm": 3.4074909687042236,
      "learning_rate": 1.9825205383674183e-05,
      "loss": 5.0129,
      "step": 50
    },
    {
      "epoch": 0.05243838489774515,
      "grad_norm": 4.635189533233643,
      "learning_rate": 1.9650410767348368e-05,
      "loss": 4.9562,
      "step": 100
    },
    {
      "epoch": 0.07865757734661773,
      "grad_norm": 5.334802627563477,
      "learning_rate": 1.947561615102255e-05,
      "loss": 4.88,
      "step": 150
    },
    {
      "epoch": 0.1048767697954903,
      "grad_norm": 5.979557991027832,
      "learning_rate": 1.930082153469673e-05,
      "loss": 4.7579,
      "step": 200
    },
    {
      "epoch": 0.13109596224436287,
      "grad_norm": 6.145437240600586,
      "learning_rate": 1.9126026918370913e-05,
      "loss": 4.6417,
      "step": 250
    },
    {
      "epoch": 0.15731515469323545,
      "grad_norm": 6.342186450958252,
      "learning_rate": 1.8951232302045098e-05,
      "loss": 4.4893,
      "step": 300
    },
    {
      "epoch": 0.18353434714210803,
      "grad_norm": 6.720129489898682,
      "learning_rate": 1.8776437685719283e-05,
      "loss": 4.3518,
      "step": 350
    },
    {
      "epoch": 0.2097535395909806,
      "grad_norm": 6.180408954620361,
      "learning_rate": 1.8601643069393465e-05,
      "loss": 4.2242,
      "step": 400
    },
    {
      "epoch": 0.23597273203985317,
      "grad_norm": 7.015050888061523,
      "learning_rate": 1.8426848453067646e-05,
      "loss": 4.0495,
      "step": 450
    },
    {
      "epoch": 0.26219192448872575,
      "grad_norm": 7.398268222808838,
      "learning_rate": 1.825205383674183e-05,
      "loss": 3.9251,
      "step": 500
    },
    {
      "epoch": 0.2884111169375983,
      "grad_norm": 7.252114295959473,
      "learning_rate": 1.8077259220416013e-05,
      "loss": 3.7802,
      "step": 550
    },
    {
      "epoch": 0.3146303093864709,
      "grad_norm": 7.438183307647705,
      "learning_rate": 1.7902464604090195e-05,
      "loss": 3.7123,
      "step": 600
    },
    {
      "epoch": 0.34084950183534346,
      "grad_norm": 7.859275817871094,
      "learning_rate": 1.7727669987764376e-05,
      "loss": 3.4836,
      "step": 650
    },
    {
      "epoch": 0.36706869428421607,
      "grad_norm": 7.805804252624512,
      "learning_rate": 1.755287537143856e-05,
      "loss": 3.3962,
      "step": 700
    },
    {
      "epoch": 0.3932878867330886,
      "grad_norm": 9.393327713012695,
      "learning_rate": 1.7378080755112743e-05,
      "loss": 3.2405,
      "step": 750
    },
    {
      "epoch": 0.4195070791819612,
      "grad_norm": 8.873008728027344,
      "learning_rate": 1.7203286138786928e-05,
      "loss": 3.1313,
      "step": 800
    },
    {
      "epoch": 0.4457262716308338,
      "grad_norm": 9.055481910705566,
      "learning_rate": 1.702849152246111e-05,
      "loss": 3.01,
      "step": 850
    },
    {
      "epoch": 0.47194546407970633,
      "grad_norm": 10.778457641601562,
      "learning_rate": 1.685369690613529e-05,
      "loss": 2.8965,
      "step": 900
    },
    {
      "epoch": 0.49816465652857894,
      "grad_norm": 9.322293281555176,
      "learning_rate": 1.6678902289809476e-05,
      "loss": 2.7984,
      "step": 950
    },
    {
      "epoch": 0.5243838489774515,
      "grad_norm": 10.097596168518066,
      "learning_rate": 1.6504107673483658e-05,
      "loss": 2.6763,
      "step": 1000
    },
    {
      "epoch": 0.5506030414263241,
      "grad_norm": 9.632770538330078,
      "learning_rate": 1.632931305715784e-05,
      "loss": 2.5972,
      "step": 1050
    },
    {
      "epoch": 0.5768222338751966,
      "grad_norm": 9.166999816894531,
      "learning_rate": 1.6154518440832024e-05,
      "loss": 2.4613,
      "step": 1100
    },
    {
      "epoch": 0.6030414263240692,
      "grad_norm": 10.514389991760254,
      "learning_rate": 1.5979723824506206e-05,
      "loss": 2.2902,
      "step": 1150
    },
    {
      "epoch": 0.6292606187729418,
      "grad_norm": 9.24748706817627,
      "learning_rate": 1.5804929208180388e-05,
      "loss": 2.2476,
      "step": 1200
    },
    {
      "epoch": 0.6554798112218144,
      "grad_norm": 8.276861190795898,
      "learning_rate": 1.5630134591854573e-05,
      "loss": 2.113,
      "step": 1250
    },
    {
      "epoch": 0.6816990036706869,
      "grad_norm": 9.379281997680664,
      "learning_rate": 1.545883586785527e-05,
      "loss": 1.9913,
      "step": 1300
    },
    {
      "epoch": 0.7079181961195595,
      "grad_norm": Infinity,
      "learning_rate": 1.528753714385597e-05,
      "loss": 1.9805,
      "step": 1350
    },
    {
      "epoch": 0.7341373885684321,
      "grad_norm": 10.03986644744873,
      "learning_rate": 1.5112742527530153e-05,
      "loss": 1.8844,
      "step": 1400
    },
    {
      "epoch": 0.7603565810173046,
      "grad_norm": 8.428816795349121,
      "learning_rate": 1.4937947911204336e-05,
      "loss": 1.789,
      "step": 1450
    },
    {
      "epoch": 0.7865757734661772,
      "grad_norm": 9.4177885055542,
      "learning_rate": 1.4763153294878518e-05,
      "loss": 1.6473,
      "step": 1500
    },
    {
      "epoch": 0.8127949659150498,
      "grad_norm": 11.008284568786621,
      "learning_rate": 1.4588358678552701e-05,
      "loss": 1.5994,
      "step": 1550
    },
    {
      "epoch": 0.8390141583639223,
      "grad_norm": 9.087879180908203,
      "learning_rate": 1.4413564062226884e-05,
      "loss": 1.5483,
      "step": 1600
    },
    {
      "epoch": 0.865233350812795,
      "grad_norm": 7.830358505249023,
      "learning_rate": 1.4238769445901068e-05,
      "loss": 1.4841,
      "step": 1650
    },
    {
      "epoch": 0.8914525432616676,
      "grad_norm": 8.461018562316895,
      "learning_rate": 1.4063974829575251e-05,
      "loss": 1.4265,
      "step": 1700
    },
    {
      "epoch": 0.9176717357105402,
      "grad_norm": 13.396951675415039,
      "learning_rate": 1.3889180213249434e-05,
      "loss": 1.33,
      "step": 1750
    },
    {
      "epoch": 0.9438909281594127,
      "grad_norm": 11.218741416931152,
      "learning_rate": 1.3714385596923616e-05,
      "loss": 1.2393,
      "step": 1800
    },
    {
      "epoch": 0.9701101206082853,
      "grad_norm": 9.90153980255127,
      "learning_rate": 1.35395909805978e-05,
      "loss": 1.2323,
      "step": 1850
    },
    {
      "epoch": 0.9963293130571579,
      "grad_norm": 8.049281120300293,
      "learning_rate": 1.3364796364271981e-05,
      "loss": 1.1652,
      "step": 1900
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.8271168569565277,
      "eval_loss": 1.328100323677063,
      "eval_runtime": 37.2669,
      "eval_samples_per_second": 147.584,
      "eval_steps_per_second": 18.461,
      "step": 1907
    }
  ],
  "logging_steps": 50,
  "max_steps": 5721,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 65440529246736.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

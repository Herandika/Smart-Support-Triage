{
  "best_metric": 0.6979219533340298,
  "best_model_checkpoint": "models\\sentiment_distilbert\\hf_outputs\\checkpoint-5702",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 17106,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008768853034023149,
      "grad_norm": 2.78609037399292,
      "learning_rate": 1.994154097977318e-05,
      "loss": 1.0106,
      "step": 50
    },
    {
      "epoch": 0.017537706068046298,
      "grad_norm": 4.405348777770996,
      "learning_rate": 1.988308195954636e-05,
      "loss": 0.9605,
      "step": 100
    },
    {
      "epoch": 0.02630655910206945,
      "grad_norm": 5.132295608520508,
      "learning_rate": 1.9825792119724076e-05,
      "loss": 0.863,
      "step": 150
    },
    {
      "epoch": 0.035075412136092596,
      "grad_norm": 15.297231674194336,
      "learning_rate": 1.9767333099497254e-05,
      "loss": 0.7744,
      "step": 200
    },
    {
      "epoch": 0.04384426517011575,
      "grad_norm": 8.914892196655273,
      "learning_rate": 1.971004325967497e-05,
      "loss": 0.8002,
      "step": 250
    },
    {
      "epoch": 0.0526131182041389,
      "grad_norm": 6.1103620529174805,
      "learning_rate": 1.965158423944815e-05,
      "loss": 0.7363,
      "step": 300
    },
    {
      "epoch": 0.061381971238162046,
      "grad_norm": 10.307082176208496,
      "learning_rate": 1.9593125219221328e-05,
      "loss": 0.716,
      "step": 350
    },
    {
      "epoch": 0.07015082427218519,
      "grad_norm": 6.216363906860352,
      "learning_rate": 1.953466619899451e-05,
      "loss": 0.8027,
      "step": 400
    },
    {
      "epoch": 0.07891967730620834,
      "grad_norm": 7.623715400695801,
      "learning_rate": 1.9476207178767687e-05,
      "loss": 0.7357,
      "step": 450
    },
    {
      "epoch": 0.0876885303402315,
      "grad_norm": 5.970484256744385,
      "learning_rate": 1.9417748158540864e-05,
      "loss": 0.7109,
      "step": 500
    },
    {
      "epoch": 0.09645738337425465,
      "grad_norm": 8.468155860900879,
      "learning_rate": 1.9359289138314042e-05,
      "loss": 0.7474,
      "step": 550
    },
    {
      "epoch": 0.1052262364082778,
      "grad_norm": 5.409418106079102,
      "learning_rate": 1.930083011808722e-05,
      "loss": 0.6828,
      "step": 600
    },
    {
      "epoch": 0.11399508944230095,
      "grad_norm": 9.056489944458008,
      "learning_rate": 1.92423710978604e-05,
      "loss": 0.7383,
      "step": 650
    },
    {
      "epoch": 0.12276394247632409,
      "grad_norm": 7.209068298339844,
      "learning_rate": 1.918391207763358e-05,
      "loss": 0.7533,
      "step": 700
    },
    {
      "epoch": 0.13153279551034724,
      "grad_norm": 11.150015830993652,
      "learning_rate": 1.912545305740676e-05,
      "loss": 0.7387,
      "step": 750
    },
    {
      "epoch": 0.14030164854437038,
      "grad_norm": 11.48244857788086,
      "learning_rate": 1.9066994037179938e-05,
      "loss": 0.736,
      "step": 800
    },
    {
      "epoch": 0.14907050157839355,
      "grad_norm": 10.70394229888916,
      "learning_rate": 1.900853501695312e-05,
      "loss": 0.6696,
      "step": 850
    },
    {
      "epoch": 0.1578393546124167,
      "grad_norm": 9.964875221252441,
      "learning_rate": 1.8950075996726297e-05,
      "loss": 0.6694,
      "step": 900
    },
    {
      "epoch": 0.16660820764643985,
      "grad_norm": 6.128086090087891,
      "learning_rate": 1.8891616976499478e-05,
      "loss": 0.7266,
      "step": 950
    },
    {
      "epoch": 0.175377060680463,
      "grad_norm": 8.196494102478027,
      "learning_rate": 1.8833157956272656e-05,
      "loss": 0.7679,
      "step": 1000
    },
    {
      "epoch": 0.18414591371448616,
      "grad_norm": 3.785667896270752,
      "learning_rate": 1.8774698936045833e-05,
      "loss": 0.7697,
      "step": 1050
    },
    {
      "epoch": 0.1929147667485093,
      "grad_norm": 6.847892761230469,
      "learning_rate": 1.871623991581901e-05,
      "loss": 0.6864,
      "step": 1100
    },
    {
      "epoch": 0.20168361978253244,
      "grad_norm": 11.189318656921387,
      "learning_rate": 1.8657780895592192e-05,
      "loss": 0.6862,
      "step": 1150
    },
    {
      "epoch": 0.2104524728165556,
      "grad_norm": 12.154191017150879,
      "learning_rate": 1.859932187536537e-05,
      "loss": 0.7452,
      "step": 1200
    },
    {
      "epoch": 0.21922132585057874,
      "grad_norm": 9.27708625793457,
      "learning_rate": 1.8540862855138548e-05,
      "loss": 0.7231,
      "step": 1250
    },
    {
      "epoch": 0.2279901788846019,
      "grad_norm": 11.412940979003906,
      "learning_rate": 1.848240383491173e-05,
      "loss": 0.739,
      "step": 1300
    },
    {
      "epoch": 0.23675903191862505,
      "grad_norm": 7.650617599487305,
      "learning_rate": 1.8423944814684907e-05,
      "loss": 0.689,
      "step": 1350
    },
    {
      "epoch": 0.24552788495264818,
      "grad_norm": 10.387537956237793,
      "learning_rate": 1.8365485794458088e-05,
      "loss": 0.7143,
      "step": 1400
    },
    {
      "epoch": 0.25429673798667135,
      "grad_norm": 5.376278400421143,
      "learning_rate": 1.8307026774231266e-05,
      "loss": 0.6391,
      "step": 1450
    },
    {
      "epoch": 0.2630655910206945,
      "grad_norm": 6.430680751800537,
      "learning_rate": 1.8248567754004443e-05,
      "loss": 0.7101,
      "step": 1500
    },
    {
      "epoch": 0.2718344440547176,
      "grad_norm": 11.026700973510742,
      "learning_rate": 1.819010873377762e-05,
      "loss": 0.6436,
      "step": 1550
    },
    {
      "epoch": 0.28060329708874077,
      "grad_norm": 19.28641700744629,
      "learning_rate": 1.8131649713550802e-05,
      "loss": 0.6819,
      "step": 1600
    },
    {
      "epoch": 0.28937215012276396,
      "grad_norm": 6.342319965362549,
      "learning_rate": 1.807319069332398e-05,
      "loss": 0.6486,
      "step": 1650
    },
    {
      "epoch": 0.2981410031567871,
      "grad_norm": 6.3827972412109375,
      "learning_rate": 1.801473167309716e-05,
      "loss": 0.6929,
      "step": 1700
    },
    {
      "epoch": 0.30690985619081024,
      "grad_norm": 6.503917217254639,
      "learning_rate": 1.795627265287034e-05,
      "loss": 0.7055,
      "step": 1750
    },
    {
      "epoch": 0.3156787092248334,
      "grad_norm": 7.862295627593994,
      "learning_rate": 1.789781363264352e-05,
      "loss": 0.624,
      "step": 1800
    },
    {
      "epoch": 0.3244475622588565,
      "grad_norm": 10.600494384765625,
      "learning_rate": 1.7839354612416698e-05,
      "loss": 0.6908,
      "step": 1850
    },
    {
      "epoch": 0.3332164152928797,
      "grad_norm": 13.644340515136719,
      "learning_rate": 1.778089559218988e-05,
      "loss": 0.6094,
      "step": 1900
    },
    {
      "epoch": 0.34198526832690285,
      "grad_norm": 6.878085136413574,
      "learning_rate": 1.7722436571963057e-05,
      "loss": 0.6287,
      "step": 1950
    },
    {
      "epoch": 0.350754121360926,
      "grad_norm": 8.99931812286377,
      "learning_rate": 1.7663977551736234e-05,
      "loss": 0.7207,
      "step": 2000
    },
    {
      "epoch": 0.3595229743949491,
      "grad_norm": 7.750284194946289,
      "learning_rate": 1.7605518531509412e-05,
      "loss": 0.6799,
      "step": 2050
    },
    {
      "epoch": 0.3682918274289723,
      "grad_norm": 11.2012939453125,
      "learning_rate": 1.754705951128259e-05,
      "loss": 0.6887,
      "step": 2100
    },
    {
      "epoch": 0.37706068046299546,
      "grad_norm": 12.072850227355957,
      "learning_rate": 1.748860049105577e-05,
      "loss": 0.6388,
      "step": 2150
    },
    {
      "epoch": 0.3858295334970186,
      "grad_norm": 9.421682357788086,
      "learning_rate": 1.743014147082895e-05,
      "loss": 0.6253,
      "step": 2200
    },
    {
      "epoch": 0.39459838653104173,
      "grad_norm": 15.51858139038086,
      "learning_rate": 1.737168245060213e-05,
      "loss": 0.6344,
      "step": 2250
    },
    {
      "epoch": 0.4033672395650649,
      "grad_norm": 8.501811981201172,
      "learning_rate": 1.7313223430375308e-05,
      "loss": 0.7072,
      "step": 2300
    },
    {
      "epoch": 0.41213609259908807,
      "grad_norm": 9.413457870483398,
      "learning_rate": 1.725476441014849e-05,
      "loss": 0.6721,
      "step": 2350
    },
    {
      "epoch": 0.4209049456331112,
      "grad_norm": 12.418612480163574,
      "learning_rate": 1.71974745703262e-05,
      "loss": 0.6842,
      "step": 2400
    },
    {
      "epoch": 0.42967379866713434,
      "grad_norm": 6.502837657928467,
      "learning_rate": 1.7139015550099382e-05,
      "loss": 0.622,
      "step": 2450
    },
    {
      "epoch": 0.4384426517011575,
      "grad_norm": 6.329768180847168,
      "learning_rate": 1.708055652987256e-05,
      "loss": 0.7045,
      "step": 2500
    },
    {
      "epoch": 0.4472115047351806,
      "grad_norm": 6.963382244110107,
      "learning_rate": 1.702209750964574e-05,
      "loss": 0.67,
      "step": 2550
    },
    {
      "epoch": 0.4559803577692038,
      "grad_norm": 4.712369918823242,
      "learning_rate": 1.696363848941892e-05,
      "loss": 0.6054,
      "step": 2600
    },
    {
      "epoch": 0.46474921080322695,
      "grad_norm": 9.84788990020752,
      "learning_rate": 1.6905179469192096e-05,
      "loss": 0.7212,
      "step": 2650
    },
    {
      "epoch": 0.4735180638372501,
      "grad_norm": 5.696516036987305,
      "learning_rate": 1.6846720448965278e-05,
      "loss": 0.6353,
      "step": 2700
    },
    {
      "epoch": 0.48228691687127323,
      "grad_norm": 7.9802327156066895,
      "learning_rate": 1.6788261428738455e-05,
      "loss": 0.7168,
      "step": 2750
    },
    {
      "epoch": 0.49105576990529637,
      "grad_norm": 11.6334228515625,
      "learning_rate": 1.6729802408511636e-05,
      "loss": 0.6892,
      "step": 2800
    },
    {
      "epoch": 0.49982462293931956,
      "grad_norm": 6.101984977722168,
      "learning_rate": 1.6671343388284814e-05,
      "loss": 0.5988,
      "step": 2850
    },
    {
      "epoch": 0.5085934759733427,
      "grad_norm": 13.859321594238281,
      "learning_rate": 1.6612884368057992e-05,
      "loss": 0.691,
      "step": 2900
    },
    {
      "epoch": 0.5173623290073658,
      "grad_norm": 9.972716331481934,
      "learning_rate": 1.655442534783117e-05,
      "loss": 0.6425,
      "step": 2950
    },
    {
      "epoch": 0.526131182041389,
      "grad_norm": 7.131099700927734,
      "learning_rate": 1.649596632760435e-05,
      "loss": 0.645,
      "step": 3000
    },
    {
      "epoch": 0.5349000350754122,
      "grad_norm": 9.994009017944336,
      "learning_rate": 1.643750730737753e-05,
      "loss": 0.5886,
      "step": 3050
    },
    {
      "epoch": 0.5436688881094353,
      "grad_norm": 5.116741180419922,
      "learning_rate": 1.637904828715071e-05,
      "loss": 0.7059,
      "step": 3100
    },
    {
      "epoch": 0.5524377411434584,
      "grad_norm": 6.788241863250732,
      "learning_rate": 1.6320589266923888e-05,
      "loss": 0.6098,
      "step": 3150
    },
    {
      "epoch": 0.5612065941774815,
      "grad_norm": 9.483665466308594,
      "learning_rate": 1.626213024669707e-05,
      "loss": 0.7098,
      "step": 3200
    },
    {
      "epoch": 0.5699754472115047,
      "grad_norm": 8.083919525146484,
      "learning_rate": 1.6203671226470246e-05,
      "loss": 0.653,
      "step": 3250
    },
    {
      "epoch": 0.5787443002455279,
      "grad_norm": 7.0439958572387695,
      "learning_rate": 1.6145212206243424e-05,
      "loss": 0.6161,
      "step": 3300
    },
    {
      "epoch": 0.587513153279551,
      "grad_norm": 5.529977798461914,
      "learning_rate": 1.6086753186016605e-05,
      "loss": 0.6665,
      "step": 3350
    },
    {
      "epoch": 0.5962820063135742,
      "grad_norm": 10.408880233764648,
      "learning_rate": 1.6028294165789783e-05,
      "loss": 0.6141,
      "step": 3400
    },
    {
      "epoch": 0.6050508593475973,
      "grad_norm": 10.851572036743164,
      "learning_rate": 1.596983514556296e-05,
      "loss": 0.5766,
      "step": 3450
    },
    {
      "epoch": 0.6138197123816205,
      "grad_norm": 8.411799430847168,
      "learning_rate": 1.591137612533614e-05,
      "loss": 0.7359,
      "step": 3500
    },
    {
      "epoch": 0.6225885654156437,
      "grad_norm": 6.488907337188721,
      "learning_rate": 1.585291710510932e-05,
      "loss": 0.6549,
      "step": 3550
    },
    {
      "epoch": 0.6313574184496668,
      "grad_norm": 10.763432502746582,
      "learning_rate": 1.5794458084882498e-05,
      "loss": 0.6894,
      "step": 3600
    },
    {
      "epoch": 0.64012627148369,
      "grad_norm": 9.205035209655762,
      "learning_rate": 1.573599906465568e-05,
      "loss": 0.632,
      "step": 3650
    },
    {
      "epoch": 0.648895124517713,
      "grad_norm": 12.431971549987793,
      "learning_rate": 1.5677540044428856e-05,
      "loss": 0.6312,
      "step": 3700
    },
    {
      "epoch": 0.6576639775517362,
      "grad_norm": 13.151571273803711,
      "learning_rate": 1.5619081024202038e-05,
      "loss": 0.6654,
      "step": 3750
    },
    {
      "epoch": 0.6664328305857594,
      "grad_norm": 8.816189765930176,
      "learning_rate": 1.5560622003975215e-05,
      "loss": 0.6495,
      "step": 3800
    },
    {
      "epoch": 0.6752016836197825,
      "grad_norm": 7.93595552444458,
      "learning_rate": 1.5502162983748393e-05,
      "loss": 0.613,
      "step": 3850
    },
    {
      "epoch": 0.6839705366538057,
      "grad_norm": 7.239200592041016,
      "learning_rate": 1.544370396352157e-05,
      "loss": 0.674,
      "step": 3900
    },
    {
      "epoch": 0.6927393896878288,
      "grad_norm": 7.882876873016357,
      "learning_rate": 1.5385244943294752e-05,
      "loss": 0.6345,
      "step": 3950
    },
    {
      "epoch": 0.701508242721852,
      "grad_norm": 6.4954833984375,
      "learning_rate": 1.532678592306793e-05,
      "loss": 0.7186,
      "step": 4000
    },
    {
      "epoch": 0.7102770957558752,
      "grad_norm": 4.600713729858398,
      "learning_rate": 1.5268326902841107e-05,
      "loss": 0.6289,
      "step": 4050
    },
    {
      "epoch": 0.7190459487898982,
      "grad_norm": 10.321553230285645,
      "learning_rate": 1.5209867882614289e-05,
      "loss": 0.5809,
      "step": 4100
    },
    {
      "epoch": 0.7278148018239214,
      "grad_norm": 9.643561363220215,
      "learning_rate": 1.5151408862387466e-05,
      "loss": 0.6228,
      "step": 4150
    },
    {
      "epoch": 0.7365836548579446,
      "grad_norm": 7.35713529586792,
      "learning_rate": 1.5092949842160648e-05,
      "loss": 0.6373,
      "step": 4200
    },
    {
      "epoch": 0.7453525078919677,
      "grad_norm": 4.078065395355225,
      "learning_rate": 1.5034490821933825e-05,
      "loss": 0.6535,
      "step": 4250
    },
    {
      "epoch": 0.7541213609259909,
      "grad_norm": 6.547789096832275,
      "learning_rate": 1.4976031801707005e-05,
      "loss": 0.644,
      "step": 4300
    },
    {
      "epoch": 0.762890213960014,
      "grad_norm": 3.811894178390503,
      "learning_rate": 1.4917572781480183e-05,
      "loss": 0.6566,
      "step": 4350
    },
    {
      "epoch": 0.7716590669940372,
      "grad_norm": 7.036433219909668,
      "learning_rate": 1.4859113761253364e-05,
      "loss": 0.6045,
      "step": 4400
    },
    {
      "epoch": 0.7804279200280604,
      "grad_norm": 9.200966835021973,
      "learning_rate": 1.4800654741026541e-05,
      "loss": 0.6145,
      "step": 4450
    },
    {
      "epoch": 0.7891967730620835,
      "grad_norm": 8.785243034362793,
      "learning_rate": 1.4742195720799721e-05,
      "loss": 0.6161,
      "step": 4500
    },
    {
      "epoch": 0.7979656260961067,
      "grad_norm": 13.086260795593262,
      "learning_rate": 1.4683736700572899e-05,
      "loss": 0.6052,
      "step": 4550
    },
    {
      "epoch": 0.8067344791301297,
      "grad_norm": 6.894944190979004,
      "learning_rate": 1.4626446860750616e-05,
      "loss": 0.63,
      "step": 4600
    },
    {
      "epoch": 0.8155033321641529,
      "grad_norm": 7.988692760467529,
      "learning_rate": 1.4567987840523793e-05,
      "loss": 0.5769,
      "step": 4650
    },
    {
      "epoch": 0.8242721851981761,
      "grad_norm": 9.271968841552734,
      "learning_rate": 1.4509528820296971e-05,
      "loss": 0.6251,
      "step": 4700
    },
    {
      "epoch": 0.8330410382321992,
      "grad_norm": 13.432433128356934,
      "learning_rate": 1.4451069800070152e-05,
      "loss": 0.6311,
      "step": 4750
    },
    {
      "epoch": 0.8418098912662224,
      "grad_norm": 19.611053466796875,
      "learning_rate": 1.439261077984333e-05,
      "loss": 0.6351,
      "step": 4800
    },
    {
      "epoch": 0.8505787443002455,
      "grad_norm": 17.896814346313477,
      "learning_rate": 1.433415175961651e-05,
      "loss": 0.5976,
      "step": 4850
    },
    {
      "epoch": 0.8593475973342687,
      "grad_norm": 9.070780754089355,
      "learning_rate": 1.4275692739389689e-05,
      "loss": 0.5921,
      "step": 4900
    },
    {
      "epoch": 0.8681164503682919,
      "grad_norm": 5.377007961273193,
      "learning_rate": 1.4217233719162868e-05,
      "loss": 0.6235,
      "step": 4950
    },
    {
      "epoch": 0.876885303402315,
      "grad_norm": 7.689847946166992,
      "learning_rate": 1.4158774698936046e-05,
      "loss": 0.6526,
      "step": 5000
    },
    {
      "epoch": 0.8856541564363382,
      "grad_norm": 8.640979766845703,
      "learning_rate": 1.4100315678709227e-05,
      "loss": 0.6752,
      "step": 5050
    },
    {
      "epoch": 0.8944230094703612,
      "grad_norm": 7.424570083618164,
      "learning_rate": 1.4041856658482405e-05,
      "loss": 0.6661,
      "step": 5100
    },
    {
      "epoch": 0.9031918625043844,
      "grad_norm": 20.304109573364258,
      "learning_rate": 1.3983397638255584e-05,
      "loss": 0.6471,
      "step": 5150
    },
    {
      "epoch": 0.9119607155384076,
      "grad_norm": 7.652063846588135,
      "learning_rate": 1.3924938618028762e-05,
      "loss": 0.635,
      "step": 5200
    },
    {
      "epoch": 0.9207295685724307,
      "grad_norm": 5.61309289932251,
      "learning_rate": 1.3866479597801943e-05,
      "loss": 0.6494,
      "step": 5250
    },
    {
      "epoch": 0.9294984216064539,
      "grad_norm": 11.51627254486084,
      "learning_rate": 1.3808020577575121e-05,
      "loss": 0.6111,
      "step": 5300
    },
    {
      "epoch": 0.938267274640477,
      "grad_norm": 8.385472297668457,
      "learning_rate": 1.37495615573483e-05,
      "loss": 0.6093,
      "step": 5350
    },
    {
      "epoch": 0.9470361276745002,
      "grad_norm": 7.989416599273682,
      "learning_rate": 1.3691102537121478e-05,
      "loss": 0.6081,
      "step": 5400
    },
    {
      "epoch": 0.9558049807085234,
      "grad_norm": 5.929741382598877,
      "learning_rate": 1.3632643516894656e-05,
      "loss": 0.5634,
      "step": 5450
    },
    {
      "epoch": 0.9645738337425465,
      "grad_norm": 8.158644676208496,
      "learning_rate": 1.3574184496667837e-05,
      "loss": 0.5934,
      "step": 5500
    },
    {
      "epoch": 0.9733426867765697,
      "grad_norm": 5.380097389221191,
      "learning_rate": 1.3515725476441015e-05,
      "loss": 0.6121,
      "step": 5550
    },
    {
      "epoch": 0.9821115398105927,
      "grad_norm": 12.424233436584473,
      "learning_rate": 1.3457266456214194e-05,
      "loss": 0.6257,
      "step": 5600
    },
    {
      "epoch": 0.9908803928446159,
      "grad_norm": 6.425619125366211,
      "learning_rate": 1.3398807435987374e-05,
      "loss": 0.595,
      "step": 5650
    },
    {
      "epoch": 0.9996492458786391,
      "grad_norm": 6.724080562591553,
      "learning_rate": 1.3340348415760553e-05,
      "loss": 0.642,
      "step": 5700
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6979219533340298,
      "eval_loss": 0.6643175482749939,
      "eval_runtime": 160.8306,
      "eval_samples_per_second": 76.378,
      "eval_steps_per_second": 9.55,
      "step": 5702
    },
    {
      "epoch": 1.0084180989126623,
      "grad_norm": 13.185784339904785,
      "learning_rate": 1.3281889395533731e-05,
      "loss": 0.5165,
      "step": 5750
    },
    {
      "epoch": 1.0171869519466854,
      "grad_norm": 3.195570468902588,
      "learning_rate": 1.3223430375306912e-05,
      "loss": 0.5,
      "step": 5800
    },
    {
      "epoch": 1.0259558049807085,
      "grad_norm": 7.197144031524658,
      "learning_rate": 1.316497135508009e-05,
      "loss": 0.5382,
      "step": 5850
    },
    {
      "epoch": 1.0347246580147316,
      "grad_norm": 4.68015193939209,
      "learning_rate": 1.310651233485327e-05,
      "loss": 0.5078,
      "step": 5900
    },
    {
      "epoch": 1.0434935110487549,
      "grad_norm": 10.591974258422852,
      "learning_rate": 1.3048053314626447e-05,
      "loss": 0.4374,
      "step": 5950
    },
    {
      "epoch": 1.052262364082778,
      "grad_norm": 9.651126861572266,
      "learning_rate": 1.2989594294399628e-05,
      "loss": 0.4784,
      "step": 6000
    },
    {
      "epoch": 1.061031217116801,
      "grad_norm": 6.314791202545166,
      "learning_rate": 1.2931135274172806e-05,
      "loss": 0.4718,
      "step": 6050
    },
    {
      "epoch": 1.0698000701508243,
      "grad_norm": 5.393407821655273,
      "learning_rate": 1.2872676253945986e-05,
      "loss": 0.5149,
      "step": 6100
    },
    {
      "epoch": 1.0785689231848474,
      "grad_norm": 15.326130867004395,
      "learning_rate": 1.2814217233719163e-05,
      "loss": 0.5103,
      "step": 6150
    },
    {
      "epoch": 1.0873377762188705,
      "grad_norm": 7.9577789306640625,
      "learning_rate": 1.2755758213492341e-05,
      "loss": 0.5296,
      "step": 6200
    },
    {
      "epoch": 1.0961066292528938,
      "grad_norm": 9.567963600158691,
      "learning_rate": 1.2697299193265522e-05,
      "loss": 0.4373,
      "step": 6250
    },
    {
      "epoch": 1.104875482286917,
      "grad_norm": 5.636972904205322,
      "learning_rate": 1.26388401730387e-05,
      "loss": 0.4621,
      "step": 6300
    },
    {
      "epoch": 1.11364433532094,
      "grad_norm": 15.910542488098145,
      "learning_rate": 1.258038115281188e-05,
      "loss": 0.4807,
      "step": 6350
    },
    {
      "epoch": 1.122413188354963,
      "grad_norm": 8.770207405090332,
      "learning_rate": 1.2521922132585059e-05,
      "loss": 0.5224,
      "step": 6400
    },
    {
      "epoch": 1.1311820413889864,
      "grad_norm": 9.428196907043457,
      "learning_rate": 1.2463463112358238e-05,
      "loss": 0.4878,
      "step": 6450
    },
    {
      "epoch": 1.1399508944230095,
      "grad_norm": 14.291045188903809,
      "learning_rate": 1.2405004092131416e-05,
      "loss": 0.5004,
      "step": 6500
    },
    {
      "epoch": 1.1487197474570325,
      "grad_norm": 8.06965160369873,
      "learning_rate": 1.2346545071904597e-05,
      "loss": 0.5179,
      "step": 6550
    },
    {
      "epoch": 1.1574886004910558,
      "grad_norm": 3.1708855628967285,
      "learning_rate": 1.2288086051677775e-05,
      "loss": 0.5039,
      "step": 6600
    },
    {
      "epoch": 1.166257453525079,
      "grad_norm": 6.842585563659668,
      "learning_rate": 1.2230796211855492e-05,
      "loss": 0.5786,
      "step": 6650
    },
    {
      "epoch": 1.175026306559102,
      "grad_norm": 6.977348804473877,
      "learning_rate": 1.217233719162867e-05,
      "loss": 0.4831,
      "step": 6700
    },
    {
      "epoch": 1.1837951595931253,
      "grad_norm": 14.591277122497559,
      "learning_rate": 1.2113878171401848e-05,
      "loss": 0.5341,
      "step": 6750
    },
    {
      "epoch": 1.1925640126271484,
      "grad_norm": 16.683696746826172,
      "learning_rate": 1.2055419151175027e-05,
      "loss": 0.5117,
      "step": 6800
    },
    {
      "epoch": 1.2013328656611715,
      "grad_norm": 8.87572193145752,
      "learning_rate": 1.1996960130948205e-05,
      "loss": 0.5037,
      "step": 6850
    },
    {
      "epoch": 1.2101017186951948,
      "grad_norm": 16.402578353881836,
      "learning_rate": 1.1938501110721386e-05,
      "loss": 0.5568,
      "step": 6900
    },
    {
      "epoch": 1.2188705717292179,
      "grad_norm": 7.4139323234558105,
      "learning_rate": 1.1880042090494564e-05,
      "loss": 0.5956,
      "step": 6950
    },
    {
      "epoch": 1.227639424763241,
      "grad_norm": 9.580617904663086,
      "learning_rate": 1.1821583070267743e-05,
      "loss": 0.5179,
      "step": 7000
    },
    {
      "epoch": 1.236408277797264,
      "grad_norm": 7.460948467254639,
      "learning_rate": 1.1763124050040921e-05,
      "loss": 0.4882,
      "step": 7050
    },
    {
      "epoch": 1.2451771308312873,
      "grad_norm": 10.990803718566895,
      "learning_rate": 1.1704665029814102e-05,
      "loss": 0.5291,
      "step": 7100
    },
    {
      "epoch": 1.2539459838653104,
      "grad_norm": 6.368955135345459,
      "learning_rate": 1.164620600958728e-05,
      "loss": 0.5424,
      "step": 7150
    },
    {
      "epoch": 1.2627148368993335,
      "grad_norm": 11.358160972595215,
      "learning_rate": 1.158774698936046e-05,
      "loss": 0.4601,
      "step": 7200
    },
    {
      "epoch": 1.2714836899333566,
      "grad_norm": 26.179758071899414,
      "learning_rate": 1.1529287969133639e-05,
      "loss": 0.5155,
      "step": 7250
    },
    {
      "epoch": 1.28025254296738,
      "grad_norm": 10.728906631469727,
      "learning_rate": 1.1470828948906818e-05,
      "loss": 0.4496,
      "step": 7300
    },
    {
      "epoch": 1.289021396001403,
      "grad_norm": 12.006559371948242,
      "learning_rate": 1.1412369928679996e-05,
      "loss": 0.4743,
      "step": 7350
    },
    {
      "epoch": 1.297790249035426,
      "grad_norm": 15.346386909484863,
      "learning_rate": 1.1353910908453177e-05,
      "loss": 0.5066,
      "step": 7400
    },
    {
      "epoch": 1.3065591020694494,
      "grad_norm": 17.93372344970703,
      "learning_rate": 1.1295451888226355e-05,
      "loss": 0.4752,
      "step": 7450
    },
    {
      "epoch": 1.3153279551034724,
      "grad_norm": 6.520020961761475,
      "learning_rate": 1.1236992867999533e-05,
      "loss": 0.4276,
      "step": 7500
    },
    {
      "epoch": 1.3240968081374955,
      "grad_norm": 18.699878692626953,
      "learning_rate": 1.1178533847772712e-05,
      "loss": 0.4897,
      "step": 7550
    },
    {
      "epoch": 1.3328656611715188,
      "grad_norm": 12.651447296142578,
      "learning_rate": 1.112007482754589e-05,
      "loss": 0.5375,
      "step": 7600
    },
    {
      "epoch": 1.341634514205542,
      "grad_norm": 14.601369857788086,
      "learning_rate": 1.1061615807319071e-05,
      "loss": 0.5583,
      "step": 7650
    },
    {
      "epoch": 1.350403367239565,
      "grad_norm": 7.107217788696289,
      "learning_rate": 1.1003156787092249e-05,
      "loss": 0.4544,
      "step": 7700
    },
    {
      "epoch": 1.3591722202735883,
      "grad_norm": 4.514739036560059,
      "learning_rate": 1.0944697766865428e-05,
      "loss": 0.4539,
      "step": 7750
    },
    {
      "epoch": 1.3679410733076114,
      "grad_norm": 5.166164398193359,
      "learning_rate": 1.0886238746638606e-05,
      "loss": 0.4327,
      "step": 7800
    },
    {
      "epoch": 1.3767099263416345,
      "grad_norm": 14.141812324523926,
      "learning_rate": 1.0827779726411787e-05,
      "loss": 0.547,
      "step": 7850
    },
    {
      "epoch": 1.3854787793756578,
      "grad_norm": 8.085691452026367,
      "learning_rate": 1.0769320706184965e-05,
      "loss": 0.4753,
      "step": 7900
    },
    {
      "epoch": 1.3942476324096809,
      "grad_norm": 3.319336414337158,
      "learning_rate": 1.0710861685958144e-05,
      "loss": 0.4447,
      "step": 7950
    },
    {
      "epoch": 1.403016485443704,
      "grad_norm": 11.340115547180176,
      "learning_rate": 1.0652402665731324e-05,
      "loss": 0.507,
      "step": 8000
    },
    {
      "epoch": 1.4117853384777272,
      "grad_norm": 17.51145362854004,
      "learning_rate": 1.0593943645504503e-05,
      "loss": 0.4784,
      "step": 8050
    },
    {
      "epoch": 1.4205541915117503,
      "grad_norm": 6.903362274169922,
      "learning_rate": 1.0535484625277681e-05,
      "loss": 0.4986,
      "step": 8100
    },
    {
      "epoch": 1.4293230445457734,
      "grad_norm": 14.143353462219238,
      "learning_rate": 1.047702560505086e-05,
      "loss": 0.4586,
      "step": 8150
    },
    {
      "epoch": 1.4380918975797965,
      "grad_norm": 15.857844352722168,
      "learning_rate": 1.041856658482404e-05,
      "loss": 0.495,
      "step": 8200
    },
    {
      "epoch": 1.4468607506138196,
      "grad_norm": 6.713830947875977,
      "learning_rate": 1.0360107564597218e-05,
      "loss": 0.469,
      "step": 8250
    },
    {
      "epoch": 1.4556296036478429,
      "grad_norm": 9.731610298156738,
      "learning_rate": 1.0301648544370397e-05,
      "loss": 0.4279,
      "step": 8300
    },
    {
      "epoch": 1.464398456681866,
      "grad_norm": 9.63312816619873,
      "learning_rate": 1.0243189524143575e-05,
      "loss": 0.4765,
      "step": 8350
    },
    {
      "epoch": 1.473167309715889,
      "grad_norm": 6.465417861938477,
      "learning_rate": 1.0184730503916756e-05,
      "loss": 0.4875,
      "step": 8400
    },
    {
      "epoch": 1.4819361627499124,
      "grad_norm": 9.533226013183594,
      "learning_rate": 1.0126271483689934e-05,
      "loss": 0.4628,
      "step": 8450
    },
    {
      "epoch": 1.4907050157839354,
      "grad_norm": 10.522842407226562,
      "learning_rate": 1.0067812463463113e-05,
      "loss": 0.5376,
      "step": 8500
    },
    {
      "epoch": 1.4994738688179585,
      "grad_norm": 12.263348579406738,
      "learning_rate": 1.0009353443236291e-05,
      "loss": 0.475,
      "step": 8550
    },
    {
      "epoch": 1.5082427218519818,
      "grad_norm": 18.457218170166016,
      "learning_rate": 9.950894423009472e-06,
      "loss": 0.475,
      "step": 8600
    },
    {
      "epoch": 1.517011574886005,
      "grad_norm": 7.831368923187256,
      "learning_rate": 9.893604583187186e-06,
      "loss": 0.4246,
      "step": 8650
    },
    {
      "epoch": 1.525780427920028,
      "grad_norm": 3.737313747406006,
      "learning_rate": 9.835145562960365e-06,
      "loss": 0.4889,
      "step": 8700
    },
    {
      "epoch": 1.5345492809540513,
      "grad_norm": 23.667850494384766,
      "learning_rate": 9.776686542733545e-06,
      "loss": 0.4871,
      "step": 8750
    },
    {
      "epoch": 1.5433181339880744,
      "grad_norm": 16.62641143798828,
      "learning_rate": 9.718227522506724e-06,
      "loss": 0.5258,
      "step": 8800
    },
    {
      "epoch": 1.5520869870220975,
      "grad_norm": 7.544626712799072,
      "learning_rate": 9.659768502279903e-06,
      "loss": 0.5326,
      "step": 8850
    },
    {
      "epoch": 1.5608558400561208,
      "grad_norm": 7.36379337310791,
      "learning_rate": 9.601309482053081e-06,
      "loss": 0.4466,
      "step": 8900
    },
    {
      "epoch": 1.5696246930901439,
      "grad_norm": 9.89643669128418,
      "learning_rate": 9.54285046182626e-06,
      "loss": 0.5076,
      "step": 8950
    },
    {
      "epoch": 1.578393546124167,
      "grad_norm": 8.472321510314941,
      "learning_rate": 9.48439144159944e-06,
      "loss": 0.4614,
      "step": 9000
    },
    {
      "epoch": 1.5871623991581902,
      "grad_norm": 12.222833633422852,
      "learning_rate": 9.42593242137262e-06,
      "loss": 0.5095,
      "step": 9050
    },
    {
      "epoch": 1.595931252192213,
      "grad_norm": 14.082836151123047,
      "learning_rate": 9.367473401145797e-06,
      "loss": 0.4332,
      "step": 9100
    },
    {
      "epoch": 1.6047001052262364,
      "grad_norm": 1.836118221282959,
      "learning_rate": 9.309014380918977e-06,
      "loss": 0.4922,
      "step": 9150
    },
    {
      "epoch": 1.6134689582602597,
      "grad_norm": 11.461652755737305,
      "learning_rate": 9.250555360692156e-06,
      "loss": 0.5189,
      "step": 9200
    },
    {
      "epoch": 1.6222378112942826,
      "grad_norm": 7.256875038146973,
      "learning_rate": 9.192096340465334e-06,
      "loss": 0.5479,
      "step": 9250
    },
    {
      "epoch": 1.6310066643283059,
      "grad_norm": 7.556775093078613,
      "learning_rate": 9.133637320238513e-06,
      "loss": 0.4524,
      "step": 9300
    },
    {
      "epoch": 1.639775517362329,
      "grad_norm": 7.143393039703369,
      "learning_rate": 9.075178300011693e-06,
      "loss": 0.4751,
      "step": 9350
    },
    {
      "epoch": 1.648544370396352,
      "grad_norm": 11.834745407104492,
      "learning_rate": 9.01671927978487e-06,
      "loss": 0.501,
      "step": 9400
    },
    {
      "epoch": 1.6573132234303753,
      "grad_norm": 18.979345321655273,
      "learning_rate": 8.95826025955805e-06,
      "loss": 0.431,
      "step": 9450
    },
    {
      "epoch": 1.6660820764643984,
      "grad_norm": 11.046215057373047,
      "learning_rate": 8.89980123933123e-06,
      "loss": 0.4644,
      "step": 9500
    },
    {
      "epoch": 1.6748509294984215,
      "grad_norm": 5.147363185882568,
      "learning_rate": 8.841342219104409e-06,
      "loss": 0.4914,
      "step": 9550
    },
    {
      "epoch": 1.6836197825324448,
      "grad_norm": 14.410489082336426,
      "learning_rate": 8.782883198877587e-06,
      "loss": 0.4741,
      "step": 9600
    },
    {
      "epoch": 1.692388635566468,
      "grad_norm": 6.612221717834473,
      "learning_rate": 8.724424178650766e-06,
      "loss": 0.4885,
      "step": 9650
    },
    {
      "epoch": 1.701157488600491,
      "grad_norm": 6.378579139709473,
      "learning_rate": 8.665965158423946e-06,
      "loss": 0.4327,
      "step": 9700
    },
    {
      "epoch": 1.7099263416345143,
      "grad_norm": 8.7021484375,
      "learning_rate": 8.607506138197125e-06,
      "loss": 0.5205,
      "step": 9750
    },
    {
      "epoch": 1.7186951946685374,
      "grad_norm": 8.619649887084961,
      "learning_rate": 8.549047117970305e-06,
      "loss": 0.4496,
      "step": 9800
    },
    {
      "epoch": 1.7274640477025605,
      "grad_norm": 15.8871488571167,
      "learning_rate": 8.490588097743482e-06,
      "loss": 0.46,
      "step": 9850
    },
    {
      "epoch": 1.7362329007365838,
      "grad_norm": 17.941707611083984,
      "learning_rate": 8.432129077516662e-06,
      "loss": 0.4346,
      "step": 9900
    },
    {
      "epoch": 1.7450017537706068,
      "grad_norm": 2.171929359436035,
      "learning_rate": 8.373670057289841e-06,
      "loss": 0.4653,
      "step": 9950
    },
    {
      "epoch": 1.75377060680463,
      "grad_norm": 23.38855743408203,
      "learning_rate": 8.315211037063019e-06,
      "loss": 0.4871,
      "step": 10000
    },
    {
      "epoch": 1.7625394598386532,
      "grad_norm": 13.622480392456055,
      "learning_rate": 8.256752016836198e-06,
      "loss": 0.4456,
      "step": 10050
    },
    {
      "epoch": 1.771308312872676,
      "grad_norm": 27.93704605102539,
      "learning_rate": 8.199462177013914e-06,
      "loss": 0.5058,
      "step": 10100
    },
    {
      "epoch": 1.7800771659066994,
      "grad_norm": 16.520423889160156,
      "learning_rate": 8.141003156787093e-06,
      "loss": 0.5351,
      "step": 10150
    },
    {
      "epoch": 1.7888460189407227,
      "grad_norm": 18.92119026184082,
      "learning_rate": 8.082544136560273e-06,
      "loss": 0.5089,
      "step": 10200
    },
    {
      "epoch": 1.7976148719747456,
      "grad_norm": 14.71410846710205,
      "learning_rate": 8.02408511633345e-06,
      "loss": 0.4755,
      "step": 10250
    },
    {
      "epoch": 1.8063837250087689,
      "grad_norm": 13.686258316040039,
      "learning_rate": 7.96562609610663e-06,
      "loss": 0.4709,
      "step": 10300
    },
    {
      "epoch": 1.815152578042792,
      "grad_norm": 19.550203323364258,
      "learning_rate": 7.90716707587981e-06,
      "loss": 0.484,
      "step": 10350
    },
    {
      "epoch": 1.823921431076815,
      "grad_norm": 11.703767776489258,
      "learning_rate": 7.848708055652989e-06,
      "loss": 0.4829,
      "step": 10400
    },
    {
      "epoch": 1.8326902841108383,
      "grad_norm": 16.558080673217773,
      "learning_rate": 7.790249035426166e-06,
      "loss": 0.4626,
      "step": 10450
    },
    {
      "epoch": 1.8414591371448614,
      "grad_norm": 6.549221515655518,
      "learning_rate": 7.731790015199346e-06,
      "loss": 0.4479,
      "step": 10500
    },
    {
      "epoch": 1.8502279901788845,
      "grad_norm": 9.090127944946289,
      "learning_rate": 7.673330994972525e-06,
      "loss": 0.4742,
      "step": 10550
    },
    {
      "epoch": 1.8589968432129078,
      "grad_norm": 13.27945613861084,
      "learning_rate": 7.614871974745703e-06,
      "loss": 0.4082,
      "step": 10600
    },
    {
      "epoch": 1.867765696246931,
      "grad_norm": 15.803004264831543,
      "learning_rate": 7.556412954518883e-06,
      "loss": 0.5314,
      "step": 10650
    },
    {
      "epoch": 1.876534549280954,
      "grad_norm": 10.246562004089355,
      "learning_rate": 7.497953934292061e-06,
      "loss": 0.5112,
      "step": 10700
    },
    {
      "epoch": 1.8853034023149773,
      "grad_norm": 12.728169441223145,
      "learning_rate": 7.439494914065241e-06,
      "loss": 0.5138,
      "step": 10750
    },
    {
      "epoch": 1.8940722553490004,
      "grad_norm": 8.36591911315918,
      "learning_rate": 7.381035893838419e-06,
      "loss": 0.4772,
      "step": 10800
    },
    {
      "epoch": 1.9028411083830234,
      "grad_norm": 12.449237823486328,
      "learning_rate": 7.322576873611599e-06,
      "loss": 0.4483,
      "step": 10850
    },
    {
      "epoch": 1.9116099614170468,
      "grad_norm": 13.708969116210938,
      "learning_rate": 7.264117853384778e-06,
      "loss": 0.5059,
      "step": 10900
    },
    {
      "epoch": 1.9203788144510698,
      "grad_norm": 17.763330459594727,
      "learning_rate": 7.205658833157957e-06,
      "loss": 0.4643,
      "step": 10950
    },
    {
      "epoch": 1.929147667485093,
      "grad_norm": 13.150432586669922,
      "learning_rate": 7.147199812931136e-06,
      "loss": 0.5046,
      "step": 11000
    },
    {
      "epoch": 1.9379165205191162,
      "grad_norm": 15.133369445800781,
      "learning_rate": 7.088740792704315e-06,
      "loss": 0.4693,
      "step": 11050
    },
    {
      "epoch": 1.946685373553139,
      "grad_norm": 13.052711486816406,
      "learning_rate": 7.030281772477494e-06,
      "loss": 0.4767,
      "step": 11100
    },
    {
      "epoch": 1.9554542265871624,
      "grad_norm": 19.558963775634766,
      "learning_rate": 6.971822752250673e-06,
      "loss": 0.5093,
      "step": 11150
    },
    {
      "epoch": 1.9642230796211857,
      "grad_norm": 9.343500137329102,
      "learning_rate": 6.913363732023852e-06,
      "loss": 0.4803,
      "step": 11200
    },
    {
      "epoch": 1.9729919326552086,
      "grad_norm": 19.72092056274414,
      "learning_rate": 6.854904711797031e-06,
      "loss": 0.5526,
      "step": 11250
    },
    {
      "epoch": 1.9817607856892319,
      "grad_norm": 11.944770812988281,
      "learning_rate": 6.79644569157021e-06,
      "loss": 0.5035,
      "step": 11300
    },
    {
      "epoch": 1.990529638723255,
      "grad_norm": 13.482226371765137,
      "learning_rate": 6.737986671343388e-06,
      "loss": 0.5155,
      "step": 11350
    },
    {
      "epoch": 1.999298491757278,
      "grad_norm": 10.458133697509766,
      "learning_rate": 6.679527651116568e-06,
      "loss": 0.5046,
      "step": 11400
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.6528412877825597,
      "eval_loss": 0.8335316181182861,
      "eval_runtime": 160.7148,
      "eval_samples_per_second": 76.434,
      "eval_steps_per_second": 9.557,
      "step": 11404
    },
    {
      "epoch": 2.0080673447913013,
      "grad_norm": 20.69639015197754,
      "learning_rate": 6.621068630889746e-06,
      "loss": 0.4242,
      "step": 11450
    },
    {
      "epoch": 2.0168361978253246,
      "grad_norm": 9.897467613220215,
      "learning_rate": 6.562609610662926e-06,
      "loss": 0.3381,
      "step": 11500
    },
    {
      "epoch": 2.0256050508593475,
      "grad_norm": 16.04319190979004,
      "learning_rate": 6.504150590436104e-06,
      "loss": 0.3785,
      "step": 11550
    },
    {
      "epoch": 2.034373903893371,
      "grad_norm": 8.256551742553711,
      "learning_rate": 6.445691570209284e-06,
      "loss": 0.3555,
      "step": 11600
    },
    {
      "epoch": 2.043142756927394,
      "grad_norm": 7.018147945404053,
      "learning_rate": 6.387232549982463e-06,
      "loss": 0.3404,
      "step": 11650
    },
    {
      "epoch": 2.051911609961417,
      "grad_norm": 25.4139347076416,
      "learning_rate": 6.328773529755642e-06,
      "loss": 0.3199,
      "step": 11700
    },
    {
      "epoch": 2.0606804629954403,
      "grad_norm": 6.396439552307129,
      "learning_rate": 6.270314509528821e-06,
      "loss": 0.3406,
      "step": 11750
    },
    {
      "epoch": 2.069449316029463,
      "grad_norm": 2.833927869796753,
      "learning_rate": 6.211855489302e-06,
      "loss": 0.3388,
      "step": 11800
    },
    {
      "epoch": 2.0782181690634864,
      "grad_norm": 12.289484977722168,
      "learning_rate": 6.153396469075179e-06,
      "loss": 0.343,
      "step": 11850
    },
    {
      "epoch": 2.0869870220975097,
      "grad_norm": 21.955955505371094,
      "learning_rate": 6.094937448848358e-06,
      "loss": 0.4611,
      "step": 11900
    },
    {
      "epoch": 2.0957558751315326,
      "grad_norm": 16.09769630432129,
      "learning_rate": 6.036478428621537e-06,
      "loss": 0.3734,
      "step": 11950
    },
    {
      "epoch": 2.104524728165556,
      "grad_norm": 22.933366775512695,
      "learning_rate": 5.978019408394716e-06,
      "loss": 0.3878,
      "step": 12000
    },
    {
      "epoch": 2.113293581199579,
      "grad_norm": 30.20948600769043,
      "learning_rate": 5.9195603881678946e-06,
      "loss": 0.3623,
      "step": 12050
    },
    {
      "epoch": 2.122062434233602,
      "grad_norm": 15.975641250610352,
      "learning_rate": 5.86227054834561e-06,
      "loss": 0.3428,
      "step": 12100
    },
    {
      "epoch": 2.1308312872676254,
      "grad_norm": 19.937292098999023,
      "learning_rate": 5.803811528118789e-06,
      "loss": 0.2824,
      "step": 12150
    },
    {
      "epoch": 2.1396001403016487,
      "grad_norm": 24.553590774536133,
      "learning_rate": 5.745352507891968e-06,
      "loss": 0.3713,
      "step": 12200
    },
    {
      "epoch": 2.1483689933356716,
      "grad_norm": 20.47231674194336,
      "learning_rate": 5.686893487665147e-06,
      "loss": 0.3905,
      "step": 12250
    },
    {
      "epoch": 2.157137846369695,
      "grad_norm": 19.25064468383789,
      "learning_rate": 5.628434467438326e-06,
      "loss": 0.3101,
      "step": 12300
    },
    {
      "epoch": 2.165906699403718,
      "grad_norm": 5.8204827308654785,
      "learning_rate": 5.569975447211505e-06,
      "loss": 0.4065,
      "step": 12350
    },
    {
      "epoch": 2.174675552437741,
      "grad_norm": 5.520166873931885,
      "learning_rate": 5.511516426984684e-06,
      "loss": 0.3999,
      "step": 12400
    },
    {
      "epoch": 2.1834444054717643,
      "grad_norm": 19.07500648498535,
      "learning_rate": 5.4530574067578635e-06,
      "loss": 0.3845,
      "step": 12450
    },
    {
      "epoch": 2.1922132585057876,
      "grad_norm": 8.035497665405273,
      "learning_rate": 5.394598386531043e-06,
      "loss": 0.3313,
      "step": 12500
    },
    {
      "epoch": 2.2009821115398105,
      "grad_norm": 16.120283126831055,
      "learning_rate": 5.3361393663042215e-06,
      "loss": 0.3781,
      "step": 12550
    },
    {
      "epoch": 2.209750964573834,
      "grad_norm": 17.809579849243164,
      "learning_rate": 5.277680346077401e-06,
      "loss": 0.4065,
      "step": 12600
    },
    {
      "epoch": 2.2185198176078567,
      "grad_norm": 10.905890464782715,
      "learning_rate": 5.21922132585058e-06,
      "loss": 0.2765,
      "step": 12650
    },
    {
      "epoch": 2.22728867064188,
      "grad_norm": 5.561007022857666,
      "learning_rate": 5.160762305623757e-06,
      "loss": 0.3607,
      "step": 12700
    },
    {
      "epoch": 2.2360575236759033,
      "grad_norm": 3.377140760421753,
      "learning_rate": 5.102303285396937e-06,
      "loss": 0.308,
      "step": 12750
    },
    {
      "epoch": 2.244826376709926,
      "grad_norm": 11.526042938232422,
      "learning_rate": 5.043844265170116e-06,
      "loss": 0.2885,
      "step": 12800
    },
    {
      "epoch": 2.2535952297439494,
      "grad_norm": 16.61709976196289,
      "learning_rate": 4.985385244943295e-06,
      "loss": 0.3001,
      "step": 12850
    },
    {
      "epoch": 2.2623640827779727,
      "grad_norm": 15.927016258239746,
      "learning_rate": 4.926926224716474e-06,
      "loss": 0.4378,
      "step": 12900
    },
    {
      "epoch": 2.2711329358119956,
      "grad_norm": 32.12984848022461,
      "learning_rate": 4.868467204489653e-06,
      "loss": 0.3091,
      "step": 12950
    },
    {
      "epoch": 2.279901788846019,
      "grad_norm": 8.76960563659668,
      "learning_rate": 4.810008184262832e-06,
      "loss": 0.3551,
      "step": 13000
    },
    {
      "epoch": 2.288670641880042,
      "grad_norm": 11.961380004882812,
      "learning_rate": 4.751549164036011e-06,
      "loss": 0.3269,
      "step": 13050
    },
    {
      "epoch": 2.297439494914065,
      "grad_norm": 30.731637954711914,
      "learning_rate": 4.69309014380919e-06,
      "loss": 0.3772,
      "step": 13100
    },
    {
      "epoch": 2.3062083479480884,
      "grad_norm": 12.76832389831543,
      "learning_rate": 4.634631123582369e-06,
      "loss": 0.4522,
      "step": 13150
    },
    {
      "epoch": 2.3149772009821117,
      "grad_norm": 9.96891975402832,
      "learning_rate": 4.5761721033555485e-06,
      "loss": 0.3109,
      "step": 13200
    },
    {
      "epoch": 2.3237460540161345,
      "grad_norm": 22.47431755065918,
      "learning_rate": 4.517713083128727e-06,
      "loss": 0.3303,
      "step": 13250
    },
    {
      "epoch": 2.332514907050158,
      "grad_norm": 15.638273239135742,
      "learning_rate": 4.459254062901906e-06,
      "loss": 0.317,
      "step": 13300
    },
    {
      "epoch": 2.341283760084181,
      "grad_norm": 21.706897735595703,
      "learning_rate": 4.400795042675085e-06,
      "loss": 0.3507,
      "step": 13350
    },
    {
      "epoch": 2.350052613118204,
      "grad_norm": 8.751347541809082,
      "learning_rate": 4.342336022448264e-06,
      "loss": 0.4316,
      "step": 13400
    },
    {
      "epoch": 2.3588214661522273,
      "grad_norm": 28.661148071289062,
      "learning_rate": 4.283877002221443e-06,
      "loss": 0.4054,
      "step": 13450
    },
    {
      "epoch": 2.3675903191862506,
      "grad_norm": 15.015542984008789,
      "learning_rate": 4.225417981994623e-06,
      "loss": 0.2861,
      "step": 13500
    },
    {
      "epoch": 2.3763591722202735,
      "grad_norm": 9.037528991699219,
      "learning_rate": 4.166958961767801e-06,
      "loss": 0.326,
      "step": 13550
    },
    {
      "epoch": 2.385128025254297,
      "grad_norm": 18.636594772338867,
      "learning_rate": 4.10849994154098e-06,
      "loss": 0.3645,
      "step": 13600
    },
    {
      "epoch": 2.39389687828832,
      "grad_norm": 21.87366485595703,
      "learning_rate": 4.050040921314159e-06,
      "loss": 0.3643,
      "step": 13650
    },
    {
      "epoch": 2.402665731322343,
      "grad_norm": 16.564655303955078,
      "learning_rate": 3.991581901087338e-06,
      "loss": 0.3553,
      "step": 13700
    },
    {
      "epoch": 2.4114345843563663,
      "grad_norm": 20.25253677368164,
      "learning_rate": 3.933122880860517e-06,
      "loss": 0.3468,
      "step": 13750
    },
    {
      "epoch": 2.4202034373903896,
      "grad_norm": 22.895524978637695,
      "learning_rate": 3.874663860633696e-06,
      "loss": 0.3091,
      "step": 13800
    },
    {
      "epoch": 2.4289722904244124,
      "grad_norm": 18.87746238708496,
      "learning_rate": 3.816204840406875e-06,
      "loss": 0.3453,
      "step": 13850
    },
    {
      "epoch": 2.4377411434584357,
      "grad_norm": 15.80117416381836,
      "learning_rate": 3.7577458201800544e-06,
      "loss": 0.3343,
      "step": 13900
    },
    {
      "epoch": 2.4465099964924586,
      "grad_norm": 23.940855026245117,
      "learning_rate": 3.6992867999532326e-06,
      "loss": 0.3275,
      "step": 13950
    },
    {
      "epoch": 2.455278849526482,
      "grad_norm": 1.2508057355880737,
      "learning_rate": 3.640827779726412e-06,
      "loss": 0.359,
      "step": 14000
    },
    {
      "epoch": 2.464047702560505,
      "grad_norm": 20.937145233154297,
      "learning_rate": 3.582368759499591e-06,
      "loss": 0.42,
      "step": 14050
    },
    {
      "epoch": 2.472816555594528,
      "grad_norm": 19.97529411315918,
      "learning_rate": 3.52390973927277e-06,
      "loss": 0.369,
      "step": 14100
    },
    {
      "epoch": 2.4815854086285514,
      "grad_norm": 25.953622817993164,
      "learning_rate": 3.465450719045949e-06,
      "loss": 0.3155,
      "step": 14150
    },
    {
      "epoch": 2.4903542616625747,
      "grad_norm": 15.040129661560059,
      "learning_rate": 3.406991698819128e-06,
      "loss": 0.3242,
      "step": 14200
    },
    {
      "epoch": 2.4991231146965975,
      "grad_norm": 12.27562141418457,
      "learning_rate": 3.3485326785923072e-06,
      "loss": 0.3497,
      "step": 14250
    },
    {
      "epoch": 2.507891967730621,
      "grad_norm": 21.97284698486328,
      "learning_rate": 3.2900736583654863e-06,
      "loss": 0.3826,
      "step": 14300
    },
    {
      "epoch": 2.516660820764644,
      "grad_norm": 11.367605209350586,
      "learning_rate": 3.2327838185432015e-06,
      "loss": 0.3483,
      "step": 14350
    },
    {
      "epoch": 2.525429673798667,
      "grad_norm": 21.417177200317383,
      "learning_rate": 3.1743247983163806e-06,
      "loss": 0.3202,
      "step": 14400
    },
    {
      "epoch": 2.5341985268326903,
      "grad_norm": 26.87312126159668,
      "learning_rate": 3.1158657780895596e-06,
      "loss": 0.3205,
      "step": 14450
    },
    {
      "epoch": 2.542967379866713,
      "grad_norm": 13.06787395477295,
      "learning_rate": 3.0574067578627386e-06,
      "loss": 0.3357,
      "step": 14500
    },
    {
      "epoch": 2.5517362329007365,
      "grad_norm": 16.179288864135742,
      "learning_rate": 2.9989477376359177e-06,
      "loss": 0.3195,
      "step": 14550
    },
    {
      "epoch": 2.56050508593476,
      "grad_norm": 3.4678330421447754,
      "learning_rate": 2.9404887174090963e-06,
      "loss": 0.3413,
      "step": 14600
    },
    {
      "epoch": 2.5692739389687826,
      "grad_norm": 2.1969292163848877,
      "learning_rate": 2.8820296971822753e-06,
      "loss": 0.3152,
      "step": 14650
    },
    {
      "epoch": 2.578042792002806,
      "grad_norm": 15.94720458984375,
      "learning_rate": 2.8235706769554543e-06,
      "loss": 0.2927,
      "step": 14700
    },
    {
      "epoch": 2.5868116450368293,
      "grad_norm": 28.057703018188477,
      "learning_rate": 2.7651116567286333e-06,
      "loss": 0.3702,
      "step": 14750
    },
    {
      "epoch": 2.595580498070852,
      "grad_norm": 14.629430770874023,
      "learning_rate": 2.7066526365018124e-06,
      "loss": 0.3324,
      "step": 14800
    },
    {
      "epoch": 2.6043493511048754,
      "grad_norm": 16.520347595214844,
      "learning_rate": 2.6481936162749914e-06,
      "loss": 0.2971,
      "step": 14850
    },
    {
      "epoch": 2.6131182041388987,
      "grad_norm": 66.04951477050781,
      "learning_rate": 2.589734596048171e-06,
      "loss": 0.3829,
      "step": 14900
    },
    {
      "epoch": 2.6218870571729216,
      "grad_norm": 26.474714279174805,
      "learning_rate": 2.531275575821349e-06,
      "loss": 0.3397,
      "step": 14950
    },
    {
      "epoch": 2.630655910206945,
      "grad_norm": 22.853015899658203,
      "learning_rate": 2.4728165555945285e-06,
      "loss": 0.352,
      "step": 15000
    },
    {
      "epoch": 2.639424763240968,
      "grad_norm": 8.237597465515137,
      "learning_rate": 2.4143575353677075e-06,
      "loss": 0.3274,
      "step": 15050
    },
    {
      "epoch": 2.648193616274991,
      "grad_norm": 26.798023223876953,
      "learning_rate": 2.3558985151408865e-06,
      "loss": 0.3767,
      "step": 15100
    },
    {
      "epoch": 2.6569624693090144,
      "grad_norm": 18.61756706237793,
      "learning_rate": 2.2974394949140656e-06,
      "loss": 0.3494,
      "step": 15150
    },
    {
      "epoch": 2.6657313223430377,
      "grad_norm": 4.683737277984619,
      "learning_rate": 2.2389804746872446e-06,
      "loss": 0.3378,
      "step": 15200
    },
    {
      "epoch": 2.6745001753770605,
      "grad_norm": 25.579238891601562,
      "learning_rate": 2.180521454460423e-06,
      "loss": 0.3409,
      "step": 15250
    },
    {
      "epoch": 2.683269028411084,
      "grad_norm": 0.757327139377594,
      "learning_rate": 2.1220624342336022e-06,
      "loss": 0.2972,
      "step": 15300
    },
    {
      "epoch": 2.692037881445107,
      "grad_norm": 11.122551918029785,
      "learning_rate": 2.0636034140067817e-06,
      "loss": 0.2827,
      "step": 15350
    },
    {
      "epoch": 2.70080673447913,
      "grad_norm": 23.69818687438965,
      "learning_rate": 2.0051443937799603e-06,
      "loss": 0.416,
      "step": 15400
    },
    {
      "epoch": 2.7095755875131533,
      "grad_norm": 10.48797607421875,
      "learning_rate": 1.9466853735531393e-06,
      "loss": 0.3162,
      "step": 15450
    },
    {
      "epoch": 2.7183444405471766,
      "grad_norm": 19.3734188079834,
      "learning_rate": 1.8882263533263184e-06,
      "loss": 0.3512,
      "step": 15500
    },
    {
      "epoch": 2.7271132935811995,
      "grad_norm": 8.095525741577148,
      "learning_rate": 1.8297673330994976e-06,
      "loss": 0.4102,
      "step": 15550
    },
    {
      "epoch": 2.7358821466152228,
      "grad_norm": 2.7248504161834717,
      "learning_rate": 1.7713083128726762e-06,
      "loss": 0.2883,
      "step": 15600
    },
    {
      "epoch": 2.744650999649246,
      "grad_norm": 26.53316307067871,
      "learning_rate": 1.7128492926458554e-06,
      "loss": 0.3868,
      "step": 15650
    },
    {
      "epoch": 2.753419852683269,
      "grad_norm": 37.405052185058594,
      "learning_rate": 1.6543902724190345e-06,
      "loss": 0.3224,
      "step": 15700
    },
    {
      "epoch": 2.7621887057172922,
      "grad_norm": 11.74937915802002,
      "learning_rate": 1.5959312521922135e-06,
      "loss": 0.2975,
      "step": 15750
    },
    {
      "epoch": 2.7709575587513156,
      "grad_norm": 20.710973739624023,
      "learning_rate": 1.5374722319653923e-06,
      "loss": 0.3657,
      "step": 15800
    },
    {
      "epoch": 2.7797264117853384,
      "grad_norm": 17.769811630249023,
      "learning_rate": 1.4790132117385713e-06,
      "loss": 0.3235,
      "step": 15850
    },
    {
      "epoch": 2.7884952648193617,
      "grad_norm": 17.18067169189453,
      "learning_rate": 1.4205541915117504e-06,
      "loss": 0.4254,
      "step": 15900
    },
    {
      "epoch": 2.797264117853385,
      "grad_norm": 29.219921112060547,
      "learning_rate": 1.3620951712849292e-06,
      "loss": 0.3522,
      "step": 15950
    },
    {
      "epoch": 2.806032970887408,
      "grad_norm": 28.565471649169922,
      "learning_rate": 1.3036361510581082e-06,
      "loss": 0.4227,
      "step": 16000
    },
    {
      "epoch": 2.814801823921431,
      "grad_norm": 12.155782699584961,
      "learning_rate": 1.2451771308312875e-06,
      "loss": 0.3246,
      "step": 16050
    },
    {
      "epoch": 2.8235706769554545,
      "grad_norm": 8.049681663513184,
      "learning_rate": 1.1867181106044663e-06,
      "loss": 0.373,
      "step": 16100
    },
    {
      "epoch": 2.8323395299894774,
      "grad_norm": 15.306572914123535,
      "learning_rate": 1.1282590903776453e-06,
      "loss": 0.3742,
      "step": 16150
    },
    {
      "epoch": 2.8411083830235007,
      "grad_norm": 36.728492736816406,
      "learning_rate": 1.0698000701508243e-06,
      "loss": 0.4061,
      "step": 16200
    },
    {
      "epoch": 2.8498772360575235,
      "grad_norm": 14.372894287109375,
      "learning_rate": 1.0113410499240034e-06,
      "loss": 0.346,
      "step": 16250
    },
    {
      "epoch": 2.858646089091547,
      "grad_norm": 10.40971565246582,
      "learning_rate": 9.528820296971823e-07,
      "loss": 0.3154,
      "step": 16300
    },
    {
      "epoch": 2.86741494212557,
      "grad_norm": 3.005283832550049,
      "learning_rate": 8.944230094703614e-07,
      "loss": 0.41,
      "step": 16350
    },
    {
      "epoch": 2.876183795159593,
      "grad_norm": 29.319562911987305,
      "learning_rate": 8.359639892435403e-07,
      "loss": 0.3389,
      "step": 16400
    },
    {
      "epoch": 2.8849526481936163,
      "grad_norm": 4.5239644050598145,
      "learning_rate": 7.786741494212557e-07,
      "loss": 0.337,
      "step": 16450
    },
    {
      "epoch": 2.893721501227639,
      "grad_norm": 25.440576553344727,
      "learning_rate": 7.202151291944349e-07,
      "loss": 0.3571,
      "step": 16500
    },
    {
      "epoch": 2.9024903542616625,
      "grad_norm": 5.382433891296387,
      "learning_rate": 6.629252893721503e-07,
      "loss": 0.3003,
      "step": 16550
    },
    {
      "epoch": 2.9112592072956858,
      "grad_norm": 32.93089294433594,
      "learning_rate": 6.044662691453292e-07,
      "loss": 0.2979,
      "step": 16600
    },
    {
      "epoch": 2.9200280603297086,
      "grad_norm": 24.150300979614258,
      "learning_rate": 5.460072489185082e-07,
      "loss": 0.2449,
      "step": 16650
    },
    {
      "epoch": 2.928796913363732,
      "grad_norm": 23.03719139099121,
      "learning_rate": 4.875482286916871e-07,
      "loss": 0.399,
      "step": 16700
    },
    {
      "epoch": 2.9375657663977552,
      "grad_norm": 27.502958297729492,
      "learning_rate": 4.2908920846486616e-07,
      "loss": 0.358,
      "step": 16750
    },
    {
      "epoch": 2.946334619431778,
      "grad_norm": 27.39862060546875,
      "learning_rate": 3.706301882380452e-07,
      "loss": 0.3709,
      "step": 16800
    },
    {
      "epoch": 2.9551034724658014,
      "grad_norm": 2.4113821983337402,
      "learning_rate": 3.1217116801122416e-07,
      "loss": 0.313,
      "step": 16850
    },
    {
      "epoch": 2.9638723254998247,
      "grad_norm": 23.52048110961914,
      "learning_rate": 2.5371214778440314e-07,
      "loss": 0.3124,
      "step": 16900
    },
    {
      "epoch": 2.9726411785338476,
      "grad_norm": 17.0775146484375,
      "learning_rate": 1.9525312755758214e-07,
      "loss": 0.3789,
      "step": 16950
    },
    {
      "epoch": 2.981410031567871,
      "grad_norm": 32.20616149902344,
      "learning_rate": 1.3679410733076114e-07,
      "loss": 0.3798,
      "step": 17000
    },
    {
      "epoch": 2.990178884601894,
      "grad_norm": 19.230562210083008,
      "learning_rate": 7.833508710394015e-08,
      "loss": 0.3738,
      "step": 17050
    },
    {
      "epoch": 2.998947737635917,
      "grad_norm": 12.732087135314941,
      "learning_rate": 1.9876066877119144e-08,
      "loss": 0.3301,
      "step": 17100
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.6842298128955501,
      "eval_loss": 1.0121362209320068,
      "eval_runtime": 160.6958,
      "eval_samples_per_second": 76.443,
      "eval_steps_per_second": 9.558,
      "step": 17106
    }
  ],
  "logging_steps": 50,
  "max_steps": 17106,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1494623196193536.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
